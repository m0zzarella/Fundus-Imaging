{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlEoTwcz_f-O",
        "outputId": "bd5497f0-9ec9-4bf8-a4cd-b11fe5b3c67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.7.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.6.0.66)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "  Downloading imgaug-0.2.6.tar.gz (631 kB)\n",
            "\u001b[K     |████████████████████████████████| 631 kB 32.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.21.6)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.1.1)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-py3-none-any.whl size=654017 sha256=c23efa75fbd6518cfad28b6bf1946f2d685e73c848e7c283381ab0bb2fcf61e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/72/98/3ebfdba1069a9a8eaaa7ae7265cfd67d63ef0197aaee2e5f9c\n",
            "Successfully built imgaug\n",
            "Installing collected packages: imgaug\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed imgaug-0.2.6\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "!pip install albumentations\n",
        "from albumentations import HorizontalFlip, VerticalFlip, ElasticTransform, GridDistortion, OpticalDistortion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4u-nyo5QZhm",
        "outputId": "86a485d3-5e7e-4978-c201-5e7b68efc602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqVR4TWCQh1m",
        "outputId": "544f3fe6-e153-43ff-87c6-31fbaf49e05e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DRIVE_Data\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/DRIVE_Data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gthx41ggAg5E",
        "outputId": "33659d3e-9a6d-4187-ee45-0bc6045698b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 20 - 20\n",
            "Test: 20 - 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:19<00:00,  3.98s/it]\n",
            "100%|██████████| 20/20 [00:22<00:00,  1.13s/it]\n"
          ]
        }
      ],
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path):\n",
        "    train_x = sorted(glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))   #loading the images\n",
        "    train_y = sorted(glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))  #loading the masks\n",
        "\n",
        "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.tif\")))\n",
        "    test_y = sorted(glob(os.path.join(path, \"test\", \"1st_manual\", \"*.gif\")))\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "def augment_data(images, masks, save_path, augment=True):\n",
        "    H = 512\n",
        "    W = 512\n",
        "\n",
        "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
        "        \n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]    #extracts the images\n",
        "        \n",
        "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "        x = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY);\n",
        "        #kernel = np.ones((5,5), np.uint8)\n",
        "        #x = cv2.dilate(x, kernel, iterations=1)\n",
        "         \n",
        "        y = imageio.mimread(y)[0]\n",
        "\n",
        "        if augment == True:\n",
        "            aug = HorizontalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x1 = augmented[\"image\"]\n",
        "            y1 = augmented[\"mask\"]\n",
        "\n",
        "            aug = VerticalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x2 = augmented[\"image\"]\n",
        "            y2 = augmented[\"mask\"]\n",
        "\n",
        "            aug = ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x3 = augmented['image']\n",
        "            y3 = augmented['mask']\n",
        "\n",
        "            aug = GridDistortion(p=1)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x4 = augmented['image']\n",
        "            y4 = augmented['mask']\n",
        "\n",
        "            aug = OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x5 = augmented['image']\n",
        "            y5 = augmented['mask']\n",
        "\n",
        "            X = [x, x1, x2, x3, x4, x5]\n",
        "            Y = [y, y1, y2, y3, y4, y5]\n",
        "\n",
        "        else:\n",
        "            X = [x]\n",
        "            Y = [y]\n",
        "\n",
        "        index = 0\n",
        "        for i, m in zip(X, Y):\n",
        "            i = cv2.resize(i, (W, H))\n",
        "            m = cv2.resize(m, (W, H))\n",
        "\n",
        "            if len(X) == 1:\n",
        "                tmp_image_name = f\"{name}.jpg\"\n",
        "                tmp_mask_name = f\"{name}.jpg\"\n",
        "            else:\n",
        "                tmp_image_name = f\"{name}_{index}.jpg\"\n",
        "                tmp_mask_name = f\"{name}_{index}.jpg\"\n",
        "\n",
        "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
        "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
        "\n",
        "            cv2.imwrite(image_path, i)\n",
        "            cv2.imwrite(mask_path, m)\n",
        "\n",
        "            index += 1\n",
        "\n",
        "def main():\n",
        "    np.random.seed(42)  #saves the seed data to reproduce the results \n",
        "\n",
        "    data_path = \"/content/drive/MyDrive/DRIVE_Data\"\n",
        "    (train_x, train_y), (test_x, test_y) = load_data(data_path)\n",
        "\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "    print(f\"Test: {len(test_x)} - {len(test_y)}\")\n",
        "\n",
        "   \n",
        "    create_dir(\"new_data/train/image\")\n",
        "    create_dir(\"new_data/train/mask\")\n",
        "    create_dir(\"new_data/test/image\")\n",
        "    create_dir(\"new_data/test/mask\")\n",
        "\n",
        "    augment_data(train_x, train_y, \"new_data/train/\", augment=True)\n",
        "    augment_data(test_x, test_y, \"new_data/test/\", augment=False)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAOY0m-aRmHM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import math\n",
        "\n",
        "#defining the loss functions\n",
        "def iou(y_true, y_pred):  #defining intersection over union\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def cross_entropy(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    return bce(y_true, y_pred)\n",
        "\n",
        "\n",
        "def cross_loss(y_true, y_pred):\n",
        "    return 1.0 - cross_entropy(y_true, y_pred)\n",
        "    \n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LSA1ATlRvxq",
        "outputId": "64a885bb-11e2-4fd3-df5c-d89461fc2df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 512, 512, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_232 (Conv2D)            (None, 512, 512, 64  640         ['input_12[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_222 (Batch  (None, 512, 512, 64  256        ['conv2d_232[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_222 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_222[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_233 (Conv2D)            (None, 512, 512, 64  36928       ['activation_222[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_223 (Batch  (None, 512, 512, 64  256        ['conv2d_233[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_223 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_223[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_33 (MaxPooling2D  (None, 256, 256, 64  0          ['activation_223[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_234 (Conv2D)            (None, 256, 256, 12  73856       ['max_pooling2d_33[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_224 (Batch  (None, 256, 256, 12  512        ['conv2d_234[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_224 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_224[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_235 (Conv2D)            (None, 256, 256, 12  147584      ['activation_224[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_225 (Batch  (None, 256, 256, 12  512        ['conv2d_235[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_225 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_225[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_34 (MaxPooling2D  (None, 128, 128, 12  0          ['activation_225[0][0]']         \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_236 (Conv2D)            (None, 128, 128, 25  295168      ['max_pooling2d_34[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_226 (Batch  (None, 128, 128, 25  1024       ['conv2d_236[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_226 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_226[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_237 (Conv2D)            (None, 128, 128, 25  590080      ['activation_226[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_227 (Batch  (None, 128, 128, 25  1024       ['conv2d_237[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_227 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_227[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_35 (MaxPooling2D  (None, 64, 64, 256)  0          ['activation_227[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_238 (Conv2D)            (None, 64, 64, 512)  1180160     ['max_pooling2d_35[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_228 (Batch  (None, 64, 64, 512)  2048       ['conv2d_238[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_228 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_228[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_239 (Conv2D)            (None, 64, 64, 512)  2359808     ['activation_228[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_229 (Batch  (None, 64, 64, 512)  2048       ['conv2d_239[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_229 (Activation)    (None, 64, 64, 512)  0           ['batch_normalization_229[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_31 (Conv2DTra  (None, 128, 128, 25  524544     ['activation_229[0][0]']         \n",
            " nspose)                        6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenate)   (None, 128, 128, 51  0           ['conv2d_transpose_31[0][0]',    \n",
            "                                2)                                'activation_227[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_240 (Conv2D)            (None, 128, 128, 25  1179904     ['concatenate_31[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_230 (Batch  (None, 128, 128, 25  1024       ['conv2d_240[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_230 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_230[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_241 (Conv2D)            (None, 128, 128, 25  590080      ['activation_230[0][0]']         \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_231 (Batch  (None, 128, 128, 25  1024       ['conv2d_241[0][0]']             \n",
            " Normalization)                 6)                                                                \n",
            "                                                                                                  \n",
            " activation_231 (Activation)    (None, 128, 128, 25  0           ['batch_normalization_231[0][0]']\n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_32 (Conv2DTra  (None, 256, 256, 12  131200     ['activation_231[0][0]']         \n",
            " nspose)                        8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 256, 256, 25  0           ['conv2d_transpose_32[0][0]',    \n",
            "                                6)                                'activation_225[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_242 (Conv2D)            (None, 256, 256, 12  295040      ['concatenate_32[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_232 (Batch  (None, 256, 256, 12  512        ['conv2d_242[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_232 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_232[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_243 (Conv2D)            (None, 256, 256, 12  147584      ['activation_232[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_233 (Batch  (None, 256, 256, 12  512        ['conv2d_243[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_233 (Activation)    (None, 256, 256, 12  0           ['batch_normalization_233[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_33 (Conv2DTra  (None, 512, 512, 64  32832      ['activation_233[0][0]']         \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 512, 512, 12  0           ['conv2d_transpose_33[0][0]',    \n",
            "                                8)                                'activation_223[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_244 (Conv2D)            (None, 512, 512, 64  73792       ['concatenate_33[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_234 (Batch  (None, 512, 512, 64  256        ['conv2d_244[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_234 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_234[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_245 (Conv2D)            (None, 512, 512, 64  36928       ['activation_234[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_235 (Batch  (None, 512, 512, 64  256        ['conv2d_245[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_235 (Activation)    (None, 512, 512, 64  0           ['batch_normalization_235[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_246 (Conv2D)            (None, 512, 512, 1)  65          ['activation_235[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,707,457\n",
            "Trainable params: 7,701,825\n",
            "Non-trainable params: 5,632\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#defining the u-net monte carlo dropout model\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout, MaxPooling2D\n",
        "from keras.models import Model\n",
        "\n",
        "drop_rate = 0.5\n",
        "#drop_train = False #monte carlo dropout\n",
        "drop_train = True\n",
        "\n",
        "def conv_block(inputs, num_filters):\n",
        "    \n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "\n",
        "    return x\n",
        "\n",
        "def conv_dropout(inputs, num_filters):\n",
        "    \n",
        "    \n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = Dropout(drop_rate)(x, training = drop_train)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def encoder_dropout(inputs, num_filters):\n",
        "    x = conv_dropout(inputs, num_filters)\n",
        "    p = MaxPooling2D((2, 2))(x)\n",
        "    return x, p\n",
        "    \n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def decoder_dropout(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_dropout(x, num_filters)\n",
        "    return x\n",
        "   \n",
        "\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    e1, p1 = encoder_block(inputs, 64)\n",
        "    e2, p2 = encoder_block(p1, 128)\n",
        "    e3, p3 = encoder_block(p2, 256)\n",
        "   \n",
        "\n",
        "    base1 = conv_block(p3, 512)\n",
        "\n",
        "    \n",
        "    d1 = decoder_block(base1, e3, 256)\n",
        "    d2 = decoder_block(d1, e2, 128)\n",
        "    d3 = decoder_block(d2, e1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d3)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    input_shape = (512, 512, 1)\n",
        "    model = build_unet(input_shape)\n",
        "    model.summary()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0o_WrwNRyH2",
        "outputId": "e9d83371-a678-468d-c1ca-7682be509127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 120 - 120\n",
            "Valid: 20 - 20\n",
            "Epoch 1/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5925 - cross_loss: 0.2211 - dice_coef: 0.4075 - iou: 0.2607 - f1_m: 0.4963 - precision_m: 0.3819 - recall_m: 0.7714\n",
            "Epoch 1: val_loss improved from inf to 0.85883, saving model to files/model.h5\n",
            "60/60 [==============================] - 40s 481ms/step - loss: 0.5925 - cross_loss: 0.2211 - dice_coef: 0.4075 - iou: 0.2607 - f1_m: 0.4963 - precision_m: 0.3819 - recall_m: 0.7714 - val_loss: 0.8588 - val_cross_loss: 0.1281 - val_dice_coef: 0.1412 - val_iou: 0.0760 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4371 - cross_loss: 0.2840 - dice_coef: 0.5629 - iou: 0.3926 - f1_m: 0.6706 - precision_m: 0.5949 - recall_m: 0.7734\n",
            "Epoch 2: val_loss did not improve from 0.85883\n",
            "60/60 [==============================] - 27s 452ms/step - loss: 0.4371 - cross_loss: 0.2840 - dice_coef: 0.5629 - iou: 0.3926 - f1_m: 0.6706 - precision_m: 0.5949 - recall_m: 0.7734 - val_loss: 0.8808 - val_cross_loss: 0.2197 - val_dice_coef: 0.1192 - val_iou: 0.0634 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3929 - cross_loss: 0.2942 - dice_coef: 0.6071 - iou: 0.4367 - f1_m: 0.7031 - precision_m: 0.6450 - recall_m: 0.7769\n",
            "Epoch 3: val_loss did not improve from 0.85883\n",
            "60/60 [==============================] - 26s 430ms/step - loss: 0.3929 - cross_loss: 0.2942 - dice_coef: 0.6071 - iou: 0.4367 - f1_m: 0.7031 - precision_m: 0.6450 - recall_m: 0.7769 - val_loss: 0.9077 - val_cross_loss: 0.2654 - val_dice_coef: 0.0923 - val_iou: 0.0484 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3638 - cross_loss: 0.3000 - dice_coef: 0.6362 - iou: 0.4672 - f1_m: 0.7225 - precision_m: 0.6756 - recall_m: 0.7803\n",
            "Epoch 4: val_loss did not improve from 0.85883\n",
            "60/60 [==============================] - 27s 456ms/step - loss: 0.3638 - cross_loss: 0.3000 - dice_coef: 0.6362 - iou: 0.4672 - f1_m: 0.7225 - precision_m: 0.6756 - recall_m: 0.7803 - val_loss: 0.9272 - val_cross_loss: 0.2810 - val_dice_coef: 0.0728 - val_iou: 0.0378 - val_f1_m: 4.9274e-05 - val_precision_m: 0.0016 - val_recall_m: 2.5027e-05 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3405 - cross_loss: 0.3041 - dice_coef: 0.6595 - iou: 0.4927 - f1_m: 0.7377 - precision_m: 0.6981 - recall_m: 0.7853\n",
            "Epoch 5: val_loss did not improve from 0.85883\n",
            "60/60 [==============================] - 27s 448ms/step - loss: 0.3405 - cross_loss: 0.3041 - dice_coef: 0.6595 - iou: 0.4927 - f1_m: 0.7377 - precision_m: 0.6981 - recall_m: 0.7853 - val_loss: 0.9401 - val_cross_loss: 0.2758 - val_dice_coef: 0.0599 - val_iou: 0.0309 - val_f1_m: 0.0035 - val_precision_m: 0.0086 - val_recall_m: 0.0022 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3217 - cross_loss: 0.3072 - dice_coef: 0.6783 - iou: 0.5138 - f1_m: 0.7489 - precision_m: 0.7145 - recall_m: 0.7900\n",
            "Epoch 6: val_loss did not improve from 0.85883\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "60/60 [==============================] - 27s 457ms/step - loss: 0.3217 - cross_loss: 0.3072 - dice_coef: 0.6783 - iou: 0.5138 - f1_m: 0.7489 - precision_m: 0.7145 - recall_m: 0.7900 - val_loss: 0.8912 - val_cross_loss: 0.2770 - val_dice_coef: 0.1088 - val_iou: 0.0578 - val_f1_m: 0.0763 - val_precision_m: 0.1298 - val_recall_m: 0.0541 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3071 - cross_loss: 0.3094 - dice_coef: 0.6929 - iou: 0.5308 - f1_m: 0.7606 - precision_m: 0.7307 - recall_m: 0.7953\n",
            "Epoch 7: val_loss improved from 0.85883 to 0.76163, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 478ms/step - loss: 0.3071 - cross_loss: 0.3094 - dice_coef: 0.6929 - iou: 0.5308 - f1_m: 0.7606 - precision_m: 0.7307 - recall_m: 0.7953 - val_loss: 0.7616 - val_cross_loss: 0.2808 - val_dice_coef: 0.2384 - val_iou: 0.1364 - val_f1_m: 0.2455 - val_precision_m: 0.3206 - val_recall_m: 0.1996 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3030 - cross_loss: 0.3098 - dice_coef: 0.6970 - iou: 0.5356 - f1_m: 0.7642 - precision_m: 0.7332 - recall_m: 0.8001\n",
            "Epoch 8: val_loss improved from 0.76163 to 0.63889, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 450ms/step - loss: 0.3030 - cross_loss: 0.3098 - dice_coef: 0.6970 - iou: 0.5356 - f1_m: 0.7642 - precision_m: 0.7332 - recall_m: 0.8001 - val_loss: 0.6389 - val_cross_loss: 0.2794 - val_dice_coef: 0.3611 - val_iou: 0.2216 - val_f1_m: 0.3999 - val_precision_m: 0.4165 - val_recall_m: 0.3859 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3002 - cross_loss: 0.3102 - dice_coef: 0.6998 - iou: 0.5389 - f1_m: 0.7666 - precision_m: 0.7359 - recall_m: 0.8020\n",
            "Epoch 9: val_loss improved from 0.63889 to 0.52963, saving model to files/model.h5\n",
            "60/60 [==============================] - 30s 498ms/step - loss: 0.3002 - cross_loss: 0.3102 - dice_coef: 0.6998 - iou: 0.5389 - f1_m: 0.7666 - precision_m: 0.7359 - recall_m: 0.8020 - val_loss: 0.5296 - val_cross_loss: 0.2877 - val_dice_coef: 0.4704 - val_iou: 0.3085 - val_f1_m: 0.5285 - val_precision_m: 0.5243 - val_recall_m: 0.5352 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2976 - cross_loss: 0.3106 - dice_coef: 0.7024 - iou: 0.5419 - f1_m: 0.7686 - precision_m: 0.7383 - recall_m: 0.8036\n",
            "Epoch 10: val_loss improved from 0.52963 to 0.39518, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 468ms/step - loss: 0.2976 - cross_loss: 0.3106 - dice_coef: 0.7024 - iou: 0.5419 - f1_m: 0.7686 - precision_m: 0.7383 - recall_m: 0.8036 - val_loss: 0.3952 - val_cross_loss: 0.3063 - val_dice_coef: 0.6048 - val_iou: 0.4342 - val_f1_m: 0.7019 - val_precision_m: 0.7882 - val_recall_m: 0.6358 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2951 - cross_loss: 0.3109 - dice_coef: 0.7049 - iou: 0.5448 - f1_m: 0.7706 - precision_m: 0.7407 - recall_m: 0.8052\n",
            "Epoch 11: val_loss improved from 0.39518 to 0.32715, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 477ms/step - loss: 0.2951 - cross_loss: 0.3109 - dice_coef: 0.7049 - iou: 0.5448 - f1_m: 0.7706 - precision_m: 0.7407 - recall_m: 0.8052 - val_loss: 0.3271 - val_cross_loss: 0.3126 - val_dice_coef: 0.6729 - val_iou: 0.5073 - val_f1_m: 0.7565 - val_precision_m: 0.8277 - val_recall_m: 0.6996 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2927 - cross_loss: 0.3112 - dice_coef: 0.7073 - iou: 0.5478 - f1_m: 0.7727 - precision_m: 0.7430 - recall_m: 0.8068\n",
            "Epoch 12: val_loss improved from 0.32715 to 0.30364, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 449ms/step - loss: 0.2927 - cross_loss: 0.3112 - dice_coef: 0.7073 - iou: 0.5478 - f1_m: 0.7727 - precision_m: 0.7430 - recall_m: 0.8068 - val_loss: 0.3036 - val_cross_loss: 0.3136 - val_dice_coef: 0.6964 - val_iou: 0.5344 - val_f1_m: 0.7689 - val_precision_m: 0.8069 - val_recall_m: 0.7373 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2902 - cross_loss: 0.3115 - dice_coef: 0.7098 - iou: 0.5507 - f1_m: 0.7747 - precision_m: 0.7454 - recall_m: 0.8084\n",
            "Epoch 13: val_loss improved from 0.30364 to 0.29434, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 474ms/step - loss: 0.2902 - cross_loss: 0.3115 - dice_coef: 0.7098 - iou: 0.5507 - f1_m: 0.7747 - precision_m: 0.7454 - recall_m: 0.8084 - val_loss: 0.2943 - val_cross_loss: 0.3136 - val_dice_coef: 0.7057 - val_iou: 0.5453 - val_f1_m: 0.7741 - val_precision_m: 0.7929 - val_recall_m: 0.7593 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2878 - cross_loss: 0.3118 - dice_coef: 0.7122 - iou: 0.5536 - f1_m: 0.7766 - precision_m: 0.7477 - recall_m: 0.8099\n",
            "Epoch 14: val_loss improved from 0.29434 to 0.29059, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 457ms/step - loss: 0.2878 - cross_loss: 0.3118 - dice_coef: 0.7122 - iou: 0.5536 - f1_m: 0.7766 - precision_m: 0.7477 - recall_m: 0.8099 - val_loss: 0.2906 - val_cross_loss: 0.3136 - val_dice_coef: 0.7094 - val_iou: 0.5498 - val_f1_m: 0.7757 - val_precision_m: 0.7854 - val_recall_m: 0.7694 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2854 - cross_loss: 0.3122 - dice_coef: 0.7146 - iou: 0.5565 - f1_m: 0.7785 - precision_m: 0.7499 - recall_m: 0.8113\n",
            "Epoch 15: val_loss improved from 0.29059 to 0.28886, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 454ms/step - loss: 0.2854 - cross_loss: 0.3122 - dice_coef: 0.7146 - iou: 0.5565 - f1_m: 0.7785 - precision_m: 0.7499 - recall_m: 0.8113 - val_loss: 0.2889 - val_cross_loss: 0.3136 - val_dice_coef: 0.7111 - val_iou: 0.5519 - val_f1_m: 0.7762 - val_precision_m: 0.7824 - val_recall_m: 0.7734 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2830 - cross_loss: 0.3125 - dice_coef: 0.7170 - iou: 0.5594 - f1_m: 0.7804 - precision_m: 0.7522 - recall_m: 0.8128\n",
            "Epoch 16: val_loss improved from 0.28886 to 0.28756, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 455ms/step - loss: 0.2830 - cross_loss: 0.3125 - dice_coef: 0.7170 - iou: 0.5594 - f1_m: 0.7804 - precision_m: 0.7522 - recall_m: 0.8128 - val_loss: 0.2876 - val_cross_loss: 0.3136 - val_dice_coef: 0.7124 - val_iou: 0.5534 - val_f1_m: 0.7765 - val_precision_m: 0.7793 - val_recall_m: 0.7769 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2806 - cross_loss: 0.3128 - dice_coef: 0.7194 - iou: 0.5624 - f1_m: 0.7824 - precision_m: 0.7546 - recall_m: 0.8142\n",
            "Epoch 17: val_loss improved from 0.28756 to 0.28648, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 477ms/step - loss: 0.2806 - cross_loss: 0.3128 - dice_coef: 0.7194 - iou: 0.5624 - f1_m: 0.7824 - precision_m: 0.7546 - recall_m: 0.8142 - val_loss: 0.2865 - val_cross_loss: 0.3137 - val_dice_coef: 0.7135 - val_iou: 0.5547 - val_f1_m: 0.7763 - val_precision_m: 0.7792 - val_recall_m: 0.7768 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2782 - cross_loss: 0.3131 - dice_coef: 0.7218 - iou: 0.5653 - f1_m: 0.7844 - precision_m: 0.7570 - recall_m: 0.8157\n",
            "Epoch 18: val_loss improved from 0.28648 to 0.28570, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 448ms/step - loss: 0.2782 - cross_loss: 0.3131 - dice_coef: 0.7218 - iou: 0.5653 - f1_m: 0.7844 - precision_m: 0.7570 - recall_m: 0.8157 - val_loss: 0.2857 - val_cross_loss: 0.3138 - val_dice_coef: 0.7143 - val_iou: 0.5557 - val_f1_m: 0.7763 - val_precision_m: 0.7788 - val_recall_m: 0.7770 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2758 - cross_loss: 0.3134 - dice_coef: 0.7242 - iou: 0.5681 - f1_m: 0.7864 - precision_m: 0.7595 - recall_m: 0.8170\n",
            "Epoch 19: val_loss improved from 0.28570 to 0.28518, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 480ms/step - loss: 0.2758 - cross_loss: 0.3134 - dice_coef: 0.7242 - iou: 0.5681 - f1_m: 0.7864 - precision_m: 0.7595 - recall_m: 0.8170 - val_loss: 0.2852 - val_cross_loss: 0.3139 - val_dice_coef: 0.7148 - val_iou: 0.5563 - val_f1_m: 0.7762 - val_precision_m: 0.7786 - val_recall_m: 0.7770 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2735 - cross_loss: 0.3137 - dice_coef: 0.7265 - iou: 0.5710 - f1_m: 0.7883 - precision_m: 0.7618 - recall_m: 0.8184\n",
            "Epoch 20: val_loss improved from 0.28518 to 0.28487, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 451ms/step - loss: 0.2735 - cross_loss: 0.3137 - dice_coef: 0.7265 - iou: 0.5710 - f1_m: 0.7883 - precision_m: 0.7618 - recall_m: 0.8184 - val_loss: 0.2849 - val_cross_loss: 0.3141 - val_dice_coef: 0.7151 - val_iou: 0.5567 - val_f1_m: 0.7757 - val_precision_m: 0.7801 - val_recall_m: 0.7746 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2712 - cross_loss: 0.3140 - dice_coef: 0.7288 - iou: 0.5738 - f1_m: 0.7901 - precision_m: 0.7640 - recall_m: 0.8197\n",
            "Epoch 21: val_loss improved from 0.28487 to 0.28428, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 456ms/step - loss: 0.2712 - cross_loss: 0.3140 - dice_coef: 0.7288 - iou: 0.5738 - f1_m: 0.7901 - precision_m: 0.7640 - recall_m: 0.8197 - val_loss: 0.2843 - val_cross_loss: 0.3142 - val_dice_coef: 0.7157 - val_iou: 0.5574 - val_f1_m: 0.7754 - val_precision_m: 0.7814 - val_recall_m: 0.7727 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2690 - cross_loss: 0.3143 - dice_coef: 0.7310 - iou: 0.5765 - f1_m: 0.7919 - precision_m: 0.7662 - recall_m: 0.8211\n",
            "Epoch 22: val_loss improved from 0.28428 to 0.28388, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 472ms/step - loss: 0.2690 - cross_loss: 0.3143 - dice_coef: 0.7310 - iou: 0.5765 - f1_m: 0.7919 - precision_m: 0.7662 - recall_m: 0.8211 - val_loss: 0.2839 - val_cross_loss: 0.3144 - val_dice_coef: 0.7161 - val_iou: 0.5579 - val_f1_m: 0.7752 - val_precision_m: 0.7821 - val_recall_m: 0.7714 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2668 - cross_loss: 0.3146 - dice_coef: 0.7332 - iou: 0.5793 - f1_m: 0.7938 - precision_m: 0.7685 - recall_m: 0.8225\n",
            "Epoch 23: val_loss improved from 0.28388 to 0.28336, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 465ms/step - loss: 0.2668 - cross_loss: 0.3146 - dice_coef: 0.7332 - iou: 0.5793 - f1_m: 0.7938 - precision_m: 0.7685 - recall_m: 0.8225 - val_loss: 0.2834 - val_cross_loss: 0.3144 - val_dice_coef: 0.7166 - val_iou: 0.5585 - val_f1_m: 0.7750 - val_precision_m: 0.7821 - val_recall_m: 0.7712 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2647 - cross_loss: 0.3148 - dice_coef: 0.7353 - iou: 0.5820 - f1_m: 0.7956 - precision_m: 0.7706 - recall_m: 0.8238\n",
            "Epoch 24: val_loss improved from 0.28336 to 0.28301, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 475ms/step - loss: 0.2647 - cross_loss: 0.3148 - dice_coef: 0.7353 - iou: 0.5820 - f1_m: 0.7956 - precision_m: 0.7706 - recall_m: 0.8238 - val_loss: 0.2830 - val_cross_loss: 0.3145 - val_dice_coef: 0.7170 - val_iou: 0.5589 - val_f1_m: 0.7749 - val_precision_m: 0.7812 - val_recall_m: 0.7717 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2625 - cross_loss: 0.3151 - dice_coef: 0.7375 - iou: 0.5846 - f1_m: 0.7974 - precision_m: 0.7729 - recall_m: 0.8251\n",
            "Epoch 25: val_loss improved from 0.28301 to 0.28270, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 470ms/step - loss: 0.2625 - cross_loss: 0.3151 - dice_coef: 0.7375 - iou: 0.5846 - f1_m: 0.7974 - precision_m: 0.7729 - recall_m: 0.8251 - val_loss: 0.2827 - val_cross_loss: 0.3146 - val_dice_coef: 0.7173 - val_iou: 0.5593 - val_f1_m: 0.7746 - val_precision_m: 0.7822 - val_recall_m: 0.7701 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2604 - cross_loss: 0.3154 - dice_coef: 0.7396 - iou: 0.5873 - f1_m: 0.7992 - precision_m: 0.7750 - recall_m: 0.8265\n",
            "Epoch 26: val_loss improved from 0.28270 to 0.28249, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 475ms/step - loss: 0.2604 - cross_loss: 0.3154 - dice_coef: 0.7396 - iou: 0.5873 - f1_m: 0.7992 - precision_m: 0.7750 - recall_m: 0.8265 - val_loss: 0.2825 - val_cross_loss: 0.3147 - val_dice_coef: 0.7175 - val_iou: 0.5596 - val_f1_m: 0.7740 - val_precision_m: 0.7833 - val_recall_m: 0.7678 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2583 - cross_loss: 0.3156 - dice_coef: 0.7417 - iou: 0.5899 - f1_m: 0.8009 - precision_m: 0.7771 - recall_m: 0.8277\n",
            "Epoch 27: val_loss improved from 0.28249 to 0.28222, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 476ms/step - loss: 0.2583 - cross_loss: 0.3156 - dice_coef: 0.7417 - iou: 0.5899 - f1_m: 0.8009 - precision_m: 0.7771 - recall_m: 0.8277 - val_loss: 0.2822 - val_cross_loss: 0.3149 - val_dice_coef: 0.7178 - val_iou: 0.5599 - val_f1_m: 0.7735 - val_precision_m: 0.7852 - val_recall_m: 0.7652 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2563 - cross_loss: 0.3159 - dice_coef: 0.7437 - iou: 0.5925 - f1_m: 0.8025 - precision_m: 0.7791 - recall_m: 0.8289\n",
            "Epoch 28: val_loss improved from 0.28222 to 0.28184, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 457ms/step - loss: 0.2563 - cross_loss: 0.3159 - dice_coef: 0.7437 - iou: 0.5925 - f1_m: 0.8025 - precision_m: 0.7791 - recall_m: 0.8289 - val_loss: 0.2818 - val_cross_loss: 0.3149 - val_dice_coef: 0.7182 - val_iou: 0.5604 - val_f1_m: 0.7734 - val_precision_m: 0.7847 - val_recall_m: 0.7655 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2542 - cross_loss: 0.3161 - dice_coef: 0.7458 - iou: 0.5951 - f1_m: 0.8043 - precision_m: 0.7813 - recall_m: 0.8302\n",
            "Epoch 29: val_loss improved from 0.28184 to 0.28137, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 472ms/step - loss: 0.2542 - cross_loss: 0.3161 - dice_coef: 0.7458 - iou: 0.5951 - f1_m: 0.8043 - precision_m: 0.7813 - recall_m: 0.8302 - val_loss: 0.2814 - val_cross_loss: 0.3149 - val_dice_coef: 0.7186 - val_iou: 0.5609 - val_f1_m: 0.7734 - val_precision_m: 0.7831 - val_recall_m: 0.7670 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2523 - cross_loss: 0.3164 - dice_coef: 0.7477 - iou: 0.5976 - f1_m: 0.8060 - precision_m: 0.7834 - recall_m: 0.8315\n",
            "Epoch 30: val_loss improved from 0.28137 to 0.28113, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 469ms/step - loss: 0.2523 - cross_loss: 0.3164 - dice_coef: 0.7477 - iou: 0.5976 - f1_m: 0.8060 - precision_m: 0.7834 - recall_m: 0.8315 - val_loss: 0.2811 - val_cross_loss: 0.3150 - val_dice_coef: 0.7189 - val_iou: 0.5612 - val_f1_m: 0.7732 - val_precision_m: 0.7831 - val_recall_m: 0.7665 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2503 - cross_loss: 0.3166 - dice_coef: 0.7497 - iou: 0.6001 - f1_m: 0.8077 - precision_m: 0.7854 - recall_m: 0.8327\n",
            "Epoch 31: val_loss improved from 0.28113 to 0.28077, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 469ms/step - loss: 0.2503 - cross_loss: 0.3166 - dice_coef: 0.7497 - iou: 0.6001 - f1_m: 0.8077 - precision_m: 0.7854 - recall_m: 0.8327 - val_loss: 0.2808 - val_cross_loss: 0.3151 - val_dice_coef: 0.7192 - val_iou: 0.5617 - val_f1_m: 0.7730 - val_precision_m: 0.7834 - val_recall_m: 0.7659 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2484 - cross_loss: 0.3169 - dice_coef: 0.7516 - iou: 0.6026 - f1_m: 0.8093 - precision_m: 0.7874 - recall_m: 0.8338\n",
            "Epoch 32: val_loss improved from 0.28077 to 0.28046, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 481ms/step - loss: 0.2484 - cross_loss: 0.3169 - dice_coef: 0.7516 - iou: 0.6026 - f1_m: 0.8093 - precision_m: 0.7874 - recall_m: 0.8338 - val_loss: 0.2805 - val_cross_loss: 0.3151 - val_dice_coef: 0.7195 - val_iou: 0.5620 - val_f1_m: 0.7727 - val_precision_m: 0.7836 - val_recall_m: 0.7652 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2465 - cross_loss: 0.3171 - dice_coef: 0.7535 - iou: 0.6050 - f1_m: 0.8109 - precision_m: 0.7894 - recall_m: 0.8350\n",
            "Epoch 33: val_loss improved from 0.28046 to 0.28017, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 472ms/step - loss: 0.2465 - cross_loss: 0.3171 - dice_coef: 0.7535 - iou: 0.6050 - f1_m: 0.8109 - precision_m: 0.7894 - recall_m: 0.8350 - val_loss: 0.2802 - val_cross_loss: 0.3152 - val_dice_coef: 0.7198 - val_iou: 0.5624 - val_f1_m: 0.7725 - val_precision_m: 0.7843 - val_recall_m: 0.7641 - lr: 1.0000e-05\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2446 - cross_loss: 0.3173 - dice_coef: 0.7554 - iou: 0.6074 - f1_m: 0.8124 - precision_m: 0.7913 - recall_m: 0.8360\n",
            "Epoch 34: val_loss improved from 0.28017 to 0.27965, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 485ms/step - loss: 0.2446 - cross_loss: 0.3173 - dice_coef: 0.7554 - iou: 0.6074 - f1_m: 0.8124 - precision_m: 0.7913 - recall_m: 0.8360 - val_loss: 0.2797 - val_cross_loss: 0.3153 - val_dice_coef: 0.7203 - val_iou: 0.5630 - val_f1_m: 0.7725 - val_precision_m: 0.7847 - val_recall_m: 0.7636 - lr: 1.0000e-05\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2428 - cross_loss: 0.3175 - dice_coef: 0.7572 - iou: 0.6098 - f1_m: 0.8140 - precision_m: 0.7933 - recall_m: 0.8370\n",
            "Epoch 35: val_loss did not improve from 0.27965\n",
            "60/60 [==============================] - 26s 431ms/step - loss: 0.2428 - cross_loss: 0.3175 - dice_coef: 0.7572 - iou: 0.6098 - f1_m: 0.8140 - precision_m: 0.7933 - recall_m: 0.8370 - val_loss: 0.2797 - val_cross_loss: 0.3154 - val_dice_coef: 0.7203 - val_iou: 0.5629 - val_f1_m: 0.7718 - val_precision_m: 0.7845 - val_recall_m: 0.7627 - lr: 1.0000e-05\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2410 - cross_loss: 0.3178 - dice_coef: 0.7590 - iou: 0.6121 - f1_m: 0.8154 - precision_m: 0.7951 - recall_m: 0.8381\n",
            "Epoch 36: val_loss improved from 0.27965 to 0.27879, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 481ms/step - loss: 0.2410 - cross_loss: 0.3178 - dice_coef: 0.7590 - iou: 0.6121 - f1_m: 0.8154 - precision_m: 0.7951 - recall_m: 0.8381 - val_loss: 0.2788 - val_cross_loss: 0.3154 - val_dice_coef: 0.7212 - val_iou: 0.5641 - val_f1_m: 0.7722 - val_precision_m: 0.7831 - val_recall_m: 0.7647 - lr: 1.0000e-05\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2392 - cross_loss: 0.3180 - dice_coef: 0.7608 - iou: 0.6144 - f1_m: 0.8169 - precision_m: 0.7971 - recall_m: 0.8391\n",
            "Epoch 37: val_loss improved from 0.27879 to 0.27840, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 468ms/step - loss: 0.2392 - cross_loss: 0.3180 - dice_coef: 0.7608 - iou: 0.6144 - f1_m: 0.8169 - precision_m: 0.7971 - recall_m: 0.8391 - val_loss: 0.2784 - val_cross_loss: 0.3154 - val_dice_coef: 0.7216 - val_iou: 0.5646 - val_f1_m: 0.7720 - val_precision_m: 0.7819 - val_recall_m: 0.7655 - lr: 1.0000e-05\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2375 - cross_loss: 0.3182 - dice_coef: 0.7625 - iou: 0.6167 - f1_m: 0.8184 - precision_m: 0.7989 - recall_m: 0.8402\n",
            "Epoch 38: val_loss did not improve from 0.27840\n",
            "60/60 [==============================] - 26s 431ms/step - loss: 0.2375 - cross_loss: 0.3182 - dice_coef: 0.7625 - iou: 0.6167 - f1_m: 0.8184 - precision_m: 0.7989 - recall_m: 0.8402 - val_loss: 0.2785 - val_cross_loss: 0.3156 - val_dice_coef: 0.7215 - val_iou: 0.5644 - val_f1_m: 0.7716 - val_precision_m: 0.7846 - val_recall_m: 0.7619 - lr: 1.0000e-05\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2358 - cross_loss: 0.3184 - dice_coef: 0.7642 - iou: 0.6189 - f1_m: 0.8198 - precision_m: 0.8006 - recall_m: 0.8412\n",
            "Epoch 39: val_loss improved from 0.27840 to 0.27790, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 465ms/step - loss: 0.2358 - cross_loss: 0.3184 - dice_coef: 0.7642 - iou: 0.6189 - f1_m: 0.8198 - precision_m: 0.8006 - recall_m: 0.8412 - val_loss: 0.2779 - val_cross_loss: 0.3156 - val_dice_coef: 0.7221 - val_iou: 0.5652 - val_f1_m: 0.7716 - val_precision_m: 0.7840 - val_recall_m: 0.7626 - lr: 1.0000e-05\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2342 - cross_loss: 0.3186 - dice_coef: 0.7658 - iou: 0.6210 - f1_m: 0.8211 - precision_m: 0.8023 - recall_m: 0.8420\n",
            "Epoch 40: val_loss improved from 0.27790 to 0.27698, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 453ms/step - loss: 0.2342 - cross_loss: 0.3186 - dice_coef: 0.7658 - iou: 0.6210 - f1_m: 0.8211 - precision_m: 0.8023 - recall_m: 0.8420 - val_loss: 0.2770 - val_cross_loss: 0.3155 - val_dice_coef: 0.7230 - val_iou: 0.5663 - val_f1_m: 0.7718 - val_precision_m: 0.7801 - val_recall_m: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2327 - cross_loss: 0.3188 - dice_coef: 0.7673 - iou: 0.6229 - f1_m: 0.8222 - precision_m: 0.8038 - recall_m: 0.8428\n",
            "Epoch 41: val_loss improved from 0.27698 to 0.27647, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 471ms/step - loss: 0.2327 - cross_loss: 0.3188 - dice_coef: 0.7673 - iou: 0.6229 - f1_m: 0.8222 - precision_m: 0.8038 - recall_m: 0.8428 - val_loss: 0.2765 - val_cross_loss: 0.3154 - val_dice_coef: 0.7235 - val_iou: 0.5669 - val_f1_m: 0.7716 - val_precision_m: 0.7784 - val_recall_m: 0.7680 - lr: 1.0000e-05\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2315 - cross_loss: 0.3189 - dice_coef: 0.7685 - iou: 0.6245 - f1_m: 0.8230 - precision_m: 0.8047 - recall_m: 0.8433\n",
            "Epoch 42: val_loss did not improve from 0.27647\n",
            "60/60 [==============================] - 26s 438ms/step - loss: 0.2315 - cross_loss: 0.3189 - dice_coef: 0.7685 - iou: 0.6245 - f1_m: 0.8230 - precision_m: 0.8047 - recall_m: 0.8433 - val_loss: 0.2767 - val_cross_loss: 0.3155 - val_dice_coef: 0.7233 - val_iou: 0.5667 - val_f1_m: 0.7710 - val_precision_m: 0.7780 - val_recall_m: 0.7672 - lr: 1.0000e-05\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2311 - cross_loss: 0.3190 - dice_coef: 0.7689 - iou: 0.6251 - f1_m: 0.8226 - precision_m: 0.8042 - recall_m: 0.8431\n",
            "Epoch 43: val_loss did not improve from 0.27647\n",
            "60/60 [==============================] - 27s 450ms/step - loss: 0.2311 - cross_loss: 0.3190 - dice_coef: 0.7689 - iou: 0.6251 - f1_m: 0.8226 - precision_m: 0.8042 - recall_m: 0.8431 - val_loss: 0.2778 - val_cross_loss: 0.3150 - val_dice_coef: 0.7222 - val_iou: 0.5653 - val_f1_m: 0.7689 - val_precision_m: 0.7695 - val_recall_m: 0.7712 - lr: 1.0000e-05\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2309 - cross_loss: 0.3190 - dice_coef: 0.7691 - iou: 0.6254 - f1_m: 0.8220 - precision_m: 0.8041 - recall_m: 0.8419\n",
            "Epoch 44: val_loss improved from 0.27647 to 0.27403, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 483ms/step - loss: 0.2309 - cross_loss: 0.3190 - dice_coef: 0.7691 - iou: 0.6254 - f1_m: 0.8220 - precision_m: 0.8041 - recall_m: 0.8419 - val_loss: 0.2740 - val_cross_loss: 0.3147 - val_dice_coef: 0.7260 - val_iou: 0.5699 - val_f1_m: 0.7718 - val_precision_m: 0.7613 - val_recall_m: 0.7856 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2305 - cross_loss: 0.3191 - dice_coef: 0.7695 - iou: 0.6258 - f1_m: 0.8216 - precision_m: 0.8036 - recall_m: 0.8416\n",
            "Epoch 45: val_loss did not improve from 0.27403\n",
            "60/60 [==============================] - 26s 434ms/step - loss: 0.2305 - cross_loss: 0.3191 - dice_coef: 0.7695 - iou: 0.6258 - f1_m: 0.8216 - precision_m: 0.8036 - recall_m: 0.8416 - val_loss: 0.2749 - val_cross_loss: 0.3157 - val_dice_coef: 0.7251 - val_iou: 0.5689 - val_f1_m: 0.7708 - val_precision_m: 0.7778 - val_recall_m: 0.7672 - lr: 1.0000e-05\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2304 - cross_loss: 0.3191 - dice_coef: 0.7696 - iou: 0.6260 - f1_m: 0.8212 - precision_m: 0.8032 - recall_m: 0.8412\n",
            "Epoch 46: val_loss did not improve from 0.27403\n",
            "60/60 [==============================] - 27s 451ms/step - loss: 0.2304 - cross_loss: 0.3191 - dice_coef: 0.7696 - iou: 0.6260 - f1_m: 0.8212 - precision_m: 0.8032 - recall_m: 0.8412 - val_loss: 0.2772 - val_cross_loss: 0.3166 - val_dice_coef: 0.7228 - val_iou: 0.5660 - val_f1_m: 0.7681 - val_precision_m: 0.7950 - val_recall_m: 0.7461 - lr: 1.0000e-05\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2287 - cross_loss: 0.3193 - dice_coef: 0.7713 - iou: 0.6283 - f1_m: 0.8226 - precision_m: 0.8056 - recall_m: 0.8418\n",
            "Epoch 47: val_loss did not improve from 0.27403\n",
            "60/60 [==============================] - 26s 432ms/step - loss: 0.2287 - cross_loss: 0.3193 - dice_coef: 0.7713 - iou: 0.6283 - f1_m: 0.8226 - precision_m: 0.8056 - recall_m: 0.8418 - val_loss: 0.2778 - val_cross_loss: 0.3164 - val_dice_coef: 0.7222 - val_iou: 0.5653 - val_f1_m: 0.7672 - val_precision_m: 0.7920 - val_recall_m: 0.7467 - lr: 1.0000e-05\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2266 - cross_loss: 0.3196 - dice_coef: 0.7734 - iou: 0.6311 - f1_m: 0.8246 - precision_m: 0.8083 - recall_m: 0.8429\n",
            "Epoch 48: val_loss did not improve from 0.27403\n",
            "60/60 [==============================] - 26s 438ms/step - loss: 0.2266 - cross_loss: 0.3196 - dice_coef: 0.7734 - iou: 0.6311 - f1_m: 0.8246 - precision_m: 0.8083 - recall_m: 0.8429 - val_loss: 0.2770 - val_cross_loss: 0.3161 - val_dice_coef: 0.7230 - val_iou: 0.5663 - val_f1_m: 0.7676 - val_precision_m: 0.7843 - val_recall_m: 0.7545 - lr: 1.0000e-05\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2250 - cross_loss: 0.3198 - dice_coef: 0.7750 - iou: 0.6332 - f1_m: 0.8260 - precision_m: 0.8097 - recall_m: 0.8441\n",
            "Epoch 49: val_loss did not improve from 0.27403\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "60/60 [==============================] - 26s 431ms/step - loss: 0.2250 - cross_loss: 0.3198 - dice_coef: 0.7750 - iou: 0.6332 - f1_m: 0.8260 - precision_m: 0.8097 - recall_m: 0.8441 - val_loss: 0.2753 - val_cross_loss: 0.3163 - val_dice_coef: 0.7247 - val_iou: 0.5684 - val_f1_m: 0.7690 - val_precision_m: 0.7871 - val_recall_m: 0.7546 - lr: 1.0000e-05\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2249 - cross_loss: 0.3198 - dice_coef: 0.7751 - iou: 0.6333 - f1_m: 0.8253 - precision_m: 0.8089 - recall_m: 0.8436\n",
            "Epoch 50: val_loss improved from 0.27403 to 0.27237, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 447ms/step - loss: 0.2249 - cross_loss: 0.3198 - dice_coef: 0.7751 - iou: 0.6333 - f1_m: 0.8253 - precision_m: 0.8089 - recall_m: 0.8436 - val_loss: 0.2724 - val_cross_loss: 0.3165 - val_dice_coef: 0.7276 - val_iou: 0.5720 - val_f1_m: 0.7715 - val_precision_m: 0.7867 - val_recall_m: 0.7598 - lr: 1.0000e-06\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2233 - cross_loss: 0.3199 - dice_coef: 0.7767 - iou: 0.6355 - f1_m: 0.8273 - precision_m: 0.8113 - recall_m: 0.8452\n",
            "Epoch 51: val_loss improved from 0.27237 to 0.27235, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 456ms/step - loss: 0.2233 - cross_loss: 0.3199 - dice_coef: 0.7767 - iou: 0.6355 - f1_m: 0.8273 - precision_m: 0.8113 - recall_m: 0.8452 - val_loss: 0.2723 - val_cross_loss: 0.3165 - val_dice_coef: 0.7277 - val_iou: 0.5720 - val_f1_m: 0.7714 - val_precision_m: 0.7876 - val_recall_m: 0.7589 - lr: 1.0000e-06\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2228 - cross_loss: 0.3200 - dice_coef: 0.7772 - iou: 0.6361 - f1_m: 0.8279 - precision_m: 0.8119 - recall_m: 0.8457\n",
            "Epoch 52: val_loss improved from 0.27235 to 0.27226, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 459ms/step - loss: 0.2228 - cross_loss: 0.3200 - dice_coef: 0.7772 - iou: 0.6361 - f1_m: 0.8279 - precision_m: 0.8119 - recall_m: 0.8457 - val_loss: 0.2723 - val_cross_loss: 0.3165 - val_dice_coef: 0.7277 - val_iou: 0.5721 - val_f1_m: 0.7713 - val_precision_m: 0.7875 - val_recall_m: 0.7586 - lr: 1.0000e-06\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2224 - cross_loss: 0.3200 - dice_coef: 0.7776 - iou: 0.6366 - f1_m: 0.8283 - precision_m: 0.8124 - recall_m: 0.8460\n",
            "Epoch 53: val_loss improved from 0.27226 to 0.27219, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 457ms/step - loss: 0.2224 - cross_loss: 0.3200 - dice_coef: 0.7776 - iou: 0.6366 - f1_m: 0.8283 - precision_m: 0.8124 - recall_m: 0.8460 - val_loss: 0.2722 - val_cross_loss: 0.3165 - val_dice_coef: 0.7278 - val_iou: 0.5722 - val_f1_m: 0.7713 - val_precision_m: 0.7874 - val_recall_m: 0.7588 - lr: 1.0000e-06\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2221 - cross_loss: 0.3201 - dice_coef: 0.7779 - iou: 0.6370 - f1_m: 0.8287 - precision_m: 0.8128 - recall_m: 0.8463\n",
            "Epoch 54: val_loss improved from 0.27219 to 0.27214, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 455ms/step - loss: 0.2221 - cross_loss: 0.3201 - dice_coef: 0.7779 - iou: 0.6370 - f1_m: 0.8287 - precision_m: 0.8128 - recall_m: 0.8463 - val_loss: 0.2721 - val_cross_loss: 0.3165 - val_dice_coef: 0.7279 - val_iou: 0.5723 - val_f1_m: 0.7711 - val_precision_m: 0.7868 - val_recall_m: 0.7589 - lr: 1.0000e-06\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2218 - cross_loss: 0.3201 - dice_coef: 0.7782 - iou: 0.6374 - f1_m: 0.8290 - precision_m: 0.8132 - recall_m: 0.8466\n",
            "Epoch 55: val_loss improved from 0.27214 to 0.27210, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 480ms/step - loss: 0.2218 - cross_loss: 0.3201 - dice_coef: 0.7782 - iou: 0.6374 - f1_m: 0.8290 - precision_m: 0.8132 - recall_m: 0.8466 - val_loss: 0.2721 - val_cross_loss: 0.3165 - val_dice_coef: 0.7279 - val_iou: 0.5723 - val_f1_m: 0.7711 - val_precision_m: 0.7865 - val_recall_m: 0.7593 - lr: 1.0000e-06\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2216 - cross_loss: 0.3201 - dice_coef: 0.7784 - iou: 0.6377 - f1_m: 0.8293 - precision_m: 0.8136 - recall_m: 0.8468\n",
            "Epoch 56: val_loss improved from 0.27210 to 0.27207, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 487ms/step - loss: 0.2216 - cross_loss: 0.3201 - dice_coef: 0.7784 - iou: 0.6377 - f1_m: 0.8293 - precision_m: 0.8136 - recall_m: 0.8468 - val_loss: 0.2721 - val_cross_loss: 0.3165 - val_dice_coef: 0.7279 - val_iou: 0.5724 - val_f1_m: 0.7710 - val_precision_m: 0.7861 - val_recall_m: 0.7594 - lr: 1.0000e-06\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2213 - cross_loss: 0.3202 - dice_coef: 0.7787 - iou: 0.6381 - f1_m: 0.8296 - precision_m: 0.8139 - recall_m: 0.8470\n",
            "Epoch 57: val_loss improved from 0.27207 to 0.27207, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 479ms/step - loss: 0.2213 - cross_loss: 0.3202 - dice_coef: 0.7787 - iou: 0.6381 - f1_m: 0.8296 - precision_m: 0.8139 - recall_m: 0.8470 - val_loss: 0.2721 - val_cross_loss: 0.3165 - val_dice_coef: 0.7279 - val_iou: 0.5724 - val_f1_m: 0.7709 - val_precision_m: 0.7858 - val_recall_m: 0.7596 - lr: 1.0000e-06\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2211 - cross_loss: 0.3202 - dice_coef: 0.7789 - iou: 0.6384 - f1_m: 0.8299 - precision_m: 0.8142 - recall_m: 0.8472\n",
            "Epoch 58: val_loss improved from 0.27207 to 0.27205, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 473ms/step - loss: 0.2211 - cross_loss: 0.3202 - dice_coef: 0.7789 - iou: 0.6384 - f1_m: 0.8299 - precision_m: 0.8142 - recall_m: 0.8472 - val_loss: 0.2721 - val_cross_loss: 0.3165 - val_dice_coef: 0.7279 - val_iou: 0.5724 - val_f1_m: 0.7708 - val_precision_m: 0.7855 - val_recall_m: 0.7597 - lr: 1.0000e-06\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2209 - cross_loss: 0.3202 - dice_coef: 0.7791 - iou: 0.6387 - f1_m: 0.8301 - precision_m: 0.8144 - recall_m: 0.8474\n",
            "Epoch 59: val_loss improved from 0.27205 to 0.27204, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 458ms/step - loss: 0.2209 - cross_loss: 0.3202 - dice_coef: 0.7791 - iou: 0.6387 - f1_m: 0.8301 - precision_m: 0.8144 - recall_m: 0.8474 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7707 - val_precision_m: 0.7853 - val_recall_m: 0.7597 - lr: 1.0000e-06\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2207 - cross_loss: 0.3202 - dice_coef: 0.7793 - iou: 0.6389 - f1_m: 0.8303 - precision_m: 0.8147 - recall_m: 0.8476\n",
            "Epoch 60: val_loss did not improve from 0.27204\n",
            "60/60 [==============================] - 27s 450ms/step - loss: 0.2207 - cross_loss: 0.3202 - dice_coef: 0.7793 - iou: 0.6389 - f1_m: 0.8303 - precision_m: 0.8147 - recall_m: 0.8476 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7707 - val_precision_m: 0.7852 - val_recall_m: 0.7597 - lr: 1.0000e-06\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2205 - cross_loss: 0.3203 - dice_coef: 0.7795 - iou: 0.6392 - f1_m: 0.8305 - precision_m: 0.8150 - recall_m: 0.8477\n",
            "Epoch 61: val_loss improved from 0.27204 to 0.27203, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 449ms/step - loss: 0.2205 - cross_loss: 0.3203 - dice_coef: 0.7795 - iou: 0.6392 - f1_m: 0.8305 - precision_m: 0.8150 - recall_m: 0.8477 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7707 - val_precision_m: 0.7852 - val_recall_m: 0.7597 - lr: 1.0000e-06\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2203 - cross_loss: 0.3203 - dice_coef: 0.7797 - iou: 0.6395 - f1_m: 0.8307 - precision_m: 0.8153 - recall_m: 0.8479\n",
            "Epoch 62: val_loss did not improve from 0.27203\n",
            "60/60 [==============================] - 27s 453ms/step - loss: 0.2203 - cross_loss: 0.3203 - dice_coef: 0.7797 - iou: 0.6395 - f1_m: 0.8307 - precision_m: 0.8153 - recall_m: 0.8479 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7706 - val_precision_m: 0.7851 - val_recall_m: 0.7596 - lr: 1.0000e-06\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2201 - cross_loss: 0.3203 - dice_coef: 0.7799 - iou: 0.6398 - f1_m: 0.8309 - precision_m: 0.8155 - recall_m: 0.8480\n",
            "Epoch 63: val_loss improved from 0.27203 to 0.27202, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 455ms/step - loss: 0.2201 - cross_loss: 0.3203 - dice_coef: 0.7799 - iou: 0.6398 - f1_m: 0.8309 - precision_m: 0.8155 - recall_m: 0.8480 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7706 - val_precision_m: 0.7849 - val_recall_m: 0.7597 - lr: 1.0000e-06\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2199 - cross_loss: 0.3203 - dice_coef: 0.7801 - iou: 0.6400 - f1_m: 0.8312 - precision_m: 0.8158 - recall_m: 0.8482\n",
            "Epoch 64: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 27s 453ms/step - loss: 0.2199 - cross_loss: 0.3203 - dice_coef: 0.7801 - iou: 0.6400 - f1_m: 0.8312 - precision_m: 0.8158 - recall_m: 0.8482 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7705 - val_precision_m: 0.7849 - val_recall_m: 0.7596 - lr: 1.0000e-06\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2197 - cross_loss: 0.3203 - dice_coef: 0.7803 - iou: 0.6403 - f1_m: 0.8314 - precision_m: 0.8160 - recall_m: 0.8483\n",
            "Epoch 65: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 27s 457ms/step - loss: 0.2197 - cross_loss: 0.3203 - dice_coef: 0.7803 - iou: 0.6403 - f1_m: 0.8314 - precision_m: 0.8160 - recall_m: 0.8483 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7705 - val_precision_m: 0.7849 - val_recall_m: 0.7595 - lr: 1.0000e-06\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2195 - cross_loss: 0.3204 - dice_coef: 0.7805 - iou: 0.6405 - f1_m: 0.8316 - precision_m: 0.8163 - recall_m: 0.8485\n",
            "Epoch 66: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 26s 431ms/step - loss: 0.2195 - cross_loss: 0.3204 - dice_coef: 0.7805 - iou: 0.6405 - f1_m: 0.8316 - precision_m: 0.8163 - recall_m: 0.8485 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7704 - val_precision_m: 0.7849 - val_recall_m: 0.7594 - lr: 1.0000e-06\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2193 - cross_loss: 0.3204 - dice_coef: 0.7807 - iou: 0.6408 - f1_m: 0.8317 - precision_m: 0.8165 - recall_m: 0.8486\n",
            "Epoch 67: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 26s 440ms/step - loss: 0.2193 - cross_loss: 0.3204 - dice_coef: 0.7807 - iou: 0.6408 - f1_m: 0.8317 - precision_m: 0.8165 - recall_m: 0.8486 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7703 - val_precision_m: 0.7848 - val_recall_m: 0.7593 - lr: 1.0000e-06\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2191 - cross_loss: 0.3204 - dice_coef: 0.7809 - iou: 0.6410 - f1_m: 0.8319 - precision_m: 0.8167 - recall_m: 0.8488\n",
            "Epoch 68: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 26s 431ms/step - loss: 0.2191 - cross_loss: 0.3204 - dice_coef: 0.7809 - iou: 0.6410 - f1_m: 0.8319 - precision_m: 0.8167 - recall_m: 0.8488 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7703 - val_precision_m: 0.7848 - val_recall_m: 0.7593 - lr: 1.0000e-06\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2189 - cross_loss: 0.3204 - dice_coef: 0.7811 - iou: 0.6413 - f1_m: 0.8321 - precision_m: 0.8169 - recall_m: 0.8489\n",
            "Epoch 69: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 27s 458ms/step - loss: 0.2189 - cross_loss: 0.3204 - dice_coef: 0.7811 - iou: 0.6413 - f1_m: 0.8321 - precision_m: 0.8169 - recall_m: 0.8489 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7702 - val_precision_m: 0.7849 - val_recall_m: 0.7590 - lr: 1.0000e-06\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2188 - cross_loss: 0.3205 - dice_coef: 0.7812 - iou: 0.6415 - f1_m: 0.8323 - precision_m: 0.8172 - recall_m: 0.8490\n",
            "Epoch 70: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 27s 453ms/step - loss: 0.2188 - cross_loss: 0.3205 - dice_coef: 0.7812 - iou: 0.6415 - f1_m: 0.8323 - precision_m: 0.8172 - recall_m: 0.8490 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7702 - val_precision_m: 0.7849 - val_recall_m: 0.7589 - lr: 1.0000e-06\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2186 - cross_loss: 0.3205 - dice_coef: 0.7814 - iou: 0.6417 - f1_m: 0.8325 - precision_m: 0.8174 - recall_m: 0.8492\n",
            "Epoch 71: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 26s 435ms/step - loss: 0.2186 - cross_loss: 0.3205 - dice_coef: 0.7814 - iou: 0.6417 - f1_m: 0.8325 - precision_m: 0.8174 - recall_m: 0.8492 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7701 - val_precision_m: 0.7849 - val_recall_m: 0.7588 - lr: 1.0000e-06\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2184 - cross_loss: 0.3205 - dice_coef: 0.7816 - iou: 0.6420 - f1_m: 0.8326 - precision_m: 0.8176 - recall_m: 0.8493\n",
            "Epoch 72: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 27s 458ms/step - loss: 0.2184 - cross_loss: 0.3205 - dice_coef: 0.7816 - iou: 0.6420 - f1_m: 0.8326 - precision_m: 0.8176 - recall_m: 0.8493 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7700 - val_precision_m: 0.7849 - val_recall_m: 0.7587 - lr: 1.0000e-06\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2182 - cross_loss: 0.3205 - dice_coef: 0.7818 - iou: 0.6422 - f1_m: 0.8328 - precision_m: 0.8178 - recall_m: 0.8494\n",
            "Epoch 73: val_loss improved from 0.27202 to 0.27202, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 459ms/step - loss: 0.2182 - cross_loss: 0.3205 - dice_coef: 0.7818 - iou: 0.6422 - f1_m: 0.8328 - precision_m: 0.8178 - recall_m: 0.8494 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7701 - val_precision_m: 0.7849 - val_recall_m: 0.7587 - lr: 1.0000e-06\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2181 - cross_loss: 0.3205 - dice_coef: 0.7819 - iou: 0.6425 - f1_m: 0.8330 - precision_m: 0.8180 - recall_m: 0.8495\n",
            "Epoch 74: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 27s 452ms/step - loss: 0.2181 - cross_loss: 0.3205 - dice_coef: 0.7819 - iou: 0.6425 - f1_m: 0.8330 - precision_m: 0.8180 - recall_m: 0.8495 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7700 - val_precision_m: 0.7849 - val_recall_m: 0.7585 - lr: 1.0000e-06\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2179 - cross_loss: 0.3206 - dice_coef: 0.7821 - iou: 0.6427 - f1_m: 0.8332 - precision_m: 0.8183 - recall_m: 0.8497\n",
            "Epoch 75: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 26s 438ms/step - loss: 0.2179 - cross_loss: 0.3206 - dice_coef: 0.7821 - iou: 0.6427 - f1_m: 0.8332 - precision_m: 0.8183 - recall_m: 0.8497 - val_loss: 0.2720 - val_cross_loss: 0.3165 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7700 - val_precision_m: 0.7850 - val_recall_m: 0.7584 - lr: 1.0000e-06\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2177 - cross_loss: 0.3206 - dice_coef: 0.7823 - iou: 0.6429 - f1_m: 0.8333 - precision_m: 0.8185 - recall_m: 0.8498\n",
            "Epoch 76: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 26s 437ms/step - loss: 0.2177 - cross_loss: 0.3206 - dice_coef: 0.7823 - iou: 0.6429 - f1_m: 0.8333 - precision_m: 0.8185 - recall_m: 0.8498 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7699 - val_precision_m: 0.7851 - val_recall_m: 0.7583 - lr: 1.0000e-06\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2175 - cross_loss: 0.3206 - dice_coef: 0.7825 - iou: 0.6431 - f1_m: 0.8335 - precision_m: 0.8187 - recall_m: 0.8499\n",
            "Epoch 77: val_loss did not improve from 0.27202\n",
            "60/60 [==============================] - 26s 431ms/step - loss: 0.2175 - cross_loss: 0.3206 - dice_coef: 0.7825 - iou: 0.6431 - f1_m: 0.8335 - precision_m: 0.8187 - recall_m: 0.8499 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7699 - val_precision_m: 0.7852 - val_recall_m: 0.7581 - lr: 1.0000e-06\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2174 - cross_loss: 0.3206 - dice_coef: 0.7826 - iou: 0.6434 - f1_m: 0.8337 - precision_m: 0.8189 - recall_m: 0.8500\n",
            "Epoch 78: val_loss improved from 0.27202 to 0.27200, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 471ms/step - loss: 0.2174 - cross_loss: 0.3206 - dice_coef: 0.7826 - iou: 0.6434 - f1_m: 0.8337 - precision_m: 0.8189 - recall_m: 0.8500 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7699 - val_precision_m: 0.7852 - val_recall_m: 0.7581 - lr: 1.0000e-06\n",
            "Epoch 79/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2172 - cross_loss: 0.3206 - dice_coef: 0.7828 - iou: 0.6436 - f1_m: 0.8338 - precision_m: 0.8191 - recall_m: 0.8502\n",
            "Epoch 79: val_loss improved from 0.27200 to 0.27200, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 482ms/step - loss: 0.2172 - cross_loss: 0.3206 - dice_coef: 0.7828 - iou: 0.6436 - f1_m: 0.8338 - precision_m: 0.8191 - recall_m: 0.8502 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7698 - val_precision_m: 0.7852 - val_recall_m: 0.7580 - lr: 1.0000e-06\n",
            "Epoch 80/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2170 - cross_loss: 0.3207 - dice_coef: 0.7830 - iou: 0.6438 - f1_m: 0.8340 - precision_m: 0.8193 - recall_m: 0.8503\n",
            "Epoch 80: val_loss did not improve from 0.27200\n",
            "60/60 [==============================] - 26s 434ms/step - loss: 0.2170 - cross_loss: 0.3207 - dice_coef: 0.7830 - iou: 0.6438 - f1_m: 0.8340 - precision_m: 0.8193 - recall_m: 0.8503 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5724 - val_f1_m: 0.7698 - val_precision_m: 0.7853 - val_recall_m: 0.7579 - lr: 1.0000e-06\n",
            "Epoch 81/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2169 - cross_loss: 0.3207 - dice_coef: 0.7831 - iou: 0.6441 - f1_m: 0.8342 - precision_m: 0.8195 - recall_m: 0.8504\n",
            "Epoch 81: val_loss improved from 0.27200 to 0.27199, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 451ms/step - loss: 0.2169 - cross_loss: 0.3207 - dice_coef: 0.7831 - iou: 0.6441 - f1_m: 0.8342 - precision_m: 0.8195 - recall_m: 0.8504 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5725 - val_f1_m: 0.7698 - val_precision_m: 0.7853 - val_recall_m: 0.7578 - lr: 1.0000e-06\n",
            "Epoch 82/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2167 - cross_loss: 0.3207 - dice_coef: 0.7833 - iou: 0.6443 - f1_m: 0.8343 - precision_m: 0.8197 - recall_m: 0.8505\n",
            "Epoch 82: val_loss improved from 0.27199 to 0.27197, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 479ms/step - loss: 0.2167 - cross_loss: 0.3207 - dice_coef: 0.7833 - iou: 0.6443 - f1_m: 0.8343 - precision_m: 0.8197 - recall_m: 0.8505 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5725 - val_f1_m: 0.7698 - val_precision_m: 0.7854 - val_recall_m: 0.7578 - lr: 1.0000e-06\n",
            "Epoch 83/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2165 - cross_loss: 0.3207 - dice_coef: 0.7835 - iou: 0.6445 - f1_m: 0.8345 - precision_m: 0.8199 - recall_m: 0.8506\n",
            "Epoch 83: val_loss did not improve from 0.27197\n",
            "60/60 [==============================] - 27s 452ms/step - loss: 0.2165 - cross_loss: 0.3207 - dice_coef: 0.7835 - iou: 0.6445 - f1_m: 0.8345 - precision_m: 0.8199 - recall_m: 0.8506 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5725 - val_f1_m: 0.7697 - val_precision_m: 0.7853 - val_recall_m: 0.7576 - lr: 1.0000e-06\n",
            "Epoch 84/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2164 - cross_loss: 0.3207 - dice_coef: 0.7836 - iou: 0.6447 - f1_m: 0.8347 - precision_m: 0.8201 - recall_m: 0.8508\n",
            "Epoch 84: val_loss did not improve from 0.27197\n",
            "60/60 [==============================] - 26s 433ms/step - loss: 0.2164 - cross_loss: 0.3207 - dice_coef: 0.7836 - iou: 0.6447 - f1_m: 0.8347 - precision_m: 0.8201 - recall_m: 0.8508 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5725 - val_f1_m: 0.7696 - val_precision_m: 0.7853 - val_recall_m: 0.7574 - lr: 1.0000e-06\n",
            "Epoch 85/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2162 - cross_loss: 0.3207 - dice_coef: 0.7838 - iou: 0.6450 - f1_m: 0.8349 - precision_m: 0.8204 - recall_m: 0.8509\n",
            "Epoch 85: val_loss improved from 0.27197 to 0.27196, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 458ms/step - loss: 0.2162 - cross_loss: 0.3207 - dice_coef: 0.7838 - iou: 0.6450 - f1_m: 0.8349 - precision_m: 0.8204 - recall_m: 0.8509 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5725 - val_f1_m: 0.7696 - val_precision_m: 0.7854 - val_recall_m: 0.7574 - lr: 1.0000e-06\n",
            "Epoch 86/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2160 - cross_loss: 0.3208 - dice_coef: 0.7840 - iou: 0.6452 - f1_m: 0.8350 - precision_m: 0.8206 - recall_m: 0.8510\n",
            "Epoch 86: val_loss improved from 0.27196 to 0.27196, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 452ms/step - loss: 0.2160 - cross_loss: 0.3208 - dice_coef: 0.7840 - iou: 0.6452 - f1_m: 0.8350 - precision_m: 0.8206 - recall_m: 0.8510 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5725 - val_f1_m: 0.7696 - val_precision_m: 0.7855 - val_recall_m: 0.7572 - lr: 1.0000e-06\n",
            "Epoch 87/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2159 - cross_loss: 0.3208 - dice_coef: 0.7841 - iou: 0.6454 - f1_m: 0.8352 - precision_m: 0.8208 - recall_m: 0.8511\n",
            "Epoch 87: val_loss improved from 0.27196 to 0.27195, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 474ms/step - loss: 0.2159 - cross_loss: 0.3208 - dice_coef: 0.7841 - iou: 0.6454 - f1_m: 0.8352 - precision_m: 0.8208 - recall_m: 0.8511 - val_loss: 0.2720 - val_cross_loss: 0.3166 - val_dice_coef: 0.7280 - val_iou: 0.5725 - val_f1_m: 0.7696 - val_precision_m: 0.7856 - val_recall_m: 0.7572 - lr: 1.0000e-06\n",
            "Epoch 88/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2157 - cross_loss: 0.3208 - dice_coef: 0.7843 - iou: 0.6456 - f1_m: 0.8353 - precision_m: 0.8209 - recall_m: 0.8512\n",
            "Epoch 88: val_loss improved from 0.27195 to 0.27193, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 485ms/step - loss: 0.2157 - cross_loss: 0.3208 - dice_coef: 0.7843 - iou: 0.6456 - f1_m: 0.8353 - precision_m: 0.8209 - recall_m: 0.8512 - val_loss: 0.2719 - val_cross_loss: 0.3166 - val_dice_coef: 0.7281 - val_iou: 0.5725 - val_f1_m: 0.7696 - val_precision_m: 0.7856 - val_recall_m: 0.7572 - lr: 1.0000e-06\n",
            "Epoch 89/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2155 - cross_loss: 0.3208 - dice_coef: 0.7845 - iou: 0.6459 - f1_m: 0.8355 - precision_m: 0.8211 - recall_m: 0.8513\n",
            "Epoch 89: val_loss improved from 0.27193 to 0.27193, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 456ms/step - loss: 0.2155 - cross_loss: 0.3208 - dice_coef: 0.7845 - iou: 0.6459 - f1_m: 0.8355 - precision_m: 0.8211 - recall_m: 0.8513 - val_loss: 0.2719 - val_cross_loss: 0.3166 - val_dice_coef: 0.7281 - val_iou: 0.5725 - val_f1_m: 0.7696 - val_precision_m: 0.7857 - val_recall_m: 0.7570 - lr: 1.0000e-06\n",
            "Epoch 90/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2154 - cross_loss: 0.3208 - dice_coef: 0.7846 - iou: 0.6461 - f1_m: 0.8356 - precision_m: 0.8213 - recall_m: 0.8514\n",
            "Epoch 90: val_loss did not improve from 0.27193\n",
            "60/60 [==============================] - 27s 454ms/step - loss: 0.2154 - cross_loss: 0.3208 - dice_coef: 0.7846 - iou: 0.6461 - f1_m: 0.8356 - precision_m: 0.8213 - recall_m: 0.8514 - val_loss: 0.2719 - val_cross_loss: 0.3166 - val_dice_coef: 0.7281 - val_iou: 0.5725 - val_f1_m: 0.7695 - val_precision_m: 0.7858 - val_recall_m: 0.7568 - lr: 1.0000e-06\n",
            "Epoch 91/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2152 - cross_loss: 0.3209 - dice_coef: 0.7848 - iou: 0.6463 - f1_m: 0.8358 - precision_m: 0.8215 - recall_m: 0.8516\n",
            "Epoch 91: val_loss did not improve from 0.27193\n",
            "60/60 [==============================] - 27s 455ms/step - loss: 0.2152 - cross_loss: 0.3209 - dice_coef: 0.7848 - iou: 0.6463 - f1_m: 0.8358 - precision_m: 0.8215 - recall_m: 0.8516 - val_loss: 0.2719 - val_cross_loss: 0.3167 - val_dice_coef: 0.7281 - val_iou: 0.5725 - val_f1_m: 0.7695 - val_precision_m: 0.7859 - val_recall_m: 0.7566 - lr: 1.0000e-06\n",
            "Epoch 92/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2150 - cross_loss: 0.3209 - dice_coef: 0.7850 - iou: 0.6465 - f1_m: 0.8360 - precision_m: 0.8217 - recall_m: 0.8517\n",
            "Epoch 92: val_loss improved from 0.27193 to 0.27192, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 474ms/step - loss: 0.2150 - cross_loss: 0.3209 - dice_coef: 0.7850 - iou: 0.6465 - f1_m: 0.8360 - precision_m: 0.8217 - recall_m: 0.8517 - val_loss: 0.2719 - val_cross_loss: 0.3167 - val_dice_coef: 0.7281 - val_iou: 0.5725 - val_f1_m: 0.7694 - val_precision_m: 0.7859 - val_recall_m: 0.7565 - lr: 1.0000e-06\n",
            "Epoch 93/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2149 - cross_loss: 0.3209 - dice_coef: 0.7851 - iou: 0.6467 - f1_m: 0.8361 - precision_m: 0.8219 - recall_m: 0.8518\n",
            "Epoch 93: val_loss did not improve from 0.27192\n",
            "60/60 [==============================] - 28s 456ms/step - loss: 0.2149 - cross_loss: 0.3209 - dice_coef: 0.7851 - iou: 0.6467 - f1_m: 0.8361 - precision_m: 0.8219 - recall_m: 0.8518 - val_loss: 0.2719 - val_cross_loss: 0.3167 - val_dice_coef: 0.7281 - val_iou: 0.5725 - val_f1_m: 0.7693 - val_precision_m: 0.7859 - val_recall_m: 0.7563 - lr: 1.0000e-06\n",
            "Epoch 94/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2147 - cross_loss: 0.3209 - dice_coef: 0.7853 - iou: 0.6470 - f1_m: 0.8363 - precision_m: 0.8221 - recall_m: 0.8519\n",
            "Epoch 94: val_loss improved from 0.27192 to 0.27191, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 451ms/step - loss: 0.2147 - cross_loss: 0.3209 - dice_coef: 0.7853 - iou: 0.6470 - f1_m: 0.8363 - precision_m: 0.8221 - recall_m: 0.8519 - val_loss: 0.2719 - val_cross_loss: 0.3167 - val_dice_coef: 0.7281 - val_iou: 0.5726 - val_f1_m: 0.7693 - val_precision_m: 0.7859 - val_recall_m: 0.7562 - lr: 1.0000e-06\n",
            "Epoch 95/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2146 - cross_loss: 0.3209 - dice_coef: 0.7854 - iou: 0.6472 - f1_m: 0.8364 - precision_m: 0.8223 - recall_m: 0.8520\n",
            "Epoch 95: val_loss improved from 0.27191 to 0.27189, saving model to files/model.h5\n",
            "60/60 [==============================] - 27s 451ms/step - loss: 0.2146 - cross_loss: 0.3209 - dice_coef: 0.7854 - iou: 0.6472 - f1_m: 0.8364 - precision_m: 0.8223 - recall_m: 0.8520 - val_loss: 0.2719 - val_cross_loss: 0.3167 - val_dice_coef: 0.7281 - val_iou: 0.5726 - val_f1_m: 0.7693 - val_precision_m: 0.7860 - val_recall_m: 0.7562 - lr: 1.0000e-06\n",
            "Epoch 96/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2144 - cross_loss: 0.3210 - dice_coef: 0.7856 - iou: 0.6474 - f1_m: 0.8366 - precision_m: 0.8225 - recall_m: 0.8521\n",
            "Epoch 96: val_loss did not improve from 0.27189\n",
            "60/60 [==============================] - 27s 454ms/step - loss: 0.2144 - cross_loss: 0.3210 - dice_coef: 0.7856 - iou: 0.6474 - f1_m: 0.8366 - precision_m: 0.8225 - recall_m: 0.8521 - val_loss: 0.2719 - val_cross_loss: 0.3167 - val_dice_coef: 0.7281 - val_iou: 0.5726 - val_f1_m: 0.7692 - val_precision_m: 0.7860 - val_recall_m: 0.7561 - lr: 1.0000e-06\n",
            "Epoch 97/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2142 - cross_loss: 0.3210 - dice_coef: 0.7858 - iou: 0.6476 - f1_m: 0.8368 - precision_m: 0.8227 - recall_m: 0.8523\n",
            "Epoch 97: val_loss improved from 0.27189 to 0.27188, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 473ms/step - loss: 0.2142 - cross_loss: 0.3210 - dice_coef: 0.7858 - iou: 0.6476 - f1_m: 0.8368 - precision_m: 0.8227 - recall_m: 0.8523 - val_loss: 0.2719 - val_cross_loss: 0.3167 - val_dice_coef: 0.7281 - val_iou: 0.5726 - val_f1_m: 0.7692 - val_precision_m: 0.7860 - val_recall_m: 0.7560 - lr: 1.0000e-06\n",
            "Epoch 98/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2141 - cross_loss: 0.3210 - dice_coef: 0.7859 - iou: 0.6479 - f1_m: 0.8369 - precision_m: 0.8229 - recall_m: 0.8524\n",
            "Epoch 98: val_loss improved from 0.27188 to 0.27187, saving model to files/model.h5\n",
            "60/60 [==============================] - 28s 460ms/step - loss: 0.2141 - cross_loss: 0.3210 - dice_coef: 0.7859 - iou: 0.6479 - f1_m: 0.8369 - precision_m: 0.8229 - recall_m: 0.8524 - val_loss: 0.2719 - val_cross_loss: 0.3167 - val_dice_coef: 0.7281 - val_iou: 0.5726 - val_f1_m: 0.7692 - val_precision_m: 0.7861 - val_recall_m: 0.7559 - lr: 1.0000e-06\n",
            "Epoch 99/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2139 - cross_loss: 0.3210 - dice_coef: 0.7861 - iou: 0.6481 - f1_m: 0.8371 - precision_m: 0.8231 - recall_m: 0.8525\n",
            "Epoch 99: val_loss did not improve from 0.27187\n",
            "60/60 [==============================] - 27s 455ms/step - loss: 0.2139 - cross_loss: 0.3210 - dice_coef: 0.7861 - iou: 0.6481 - f1_m: 0.8371 - precision_m: 0.8231 - recall_m: 0.8525 - val_loss: 0.2719 - val_cross_loss: 0.3167 - val_dice_coef: 0.7281 - val_iou: 0.5726 - val_f1_m: 0.7691 - val_precision_m: 0.7862 - val_recall_m: 0.7557 - lr: 1.0000e-06\n",
            "Epoch 100/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2137 - cross_loss: 0.3210 - dice_coef: 0.7863 - iou: 0.6483 - f1_m: 0.8372 - precision_m: 0.8233 - recall_m: 0.8526\n",
            "Epoch 100: val_loss improved from 0.27187 to 0.27187, saving model to files/model.h5\n",
            "60/60 [==============================] - 29s 477ms/step - loss: 0.2137 - cross_loss: 0.3210 - dice_coef: 0.7863 - iou: 0.6483 - f1_m: 0.8372 - precision_m: 0.8233 - recall_m: 0.8526 - val_loss: 0.2719 - val_cross_loss: 0.3167 - val_dice_coef: 0.7281 - val_iou: 0.5726 - val_f1_m: 0.7691 - val_precision_m: 0.7862 - val_recall_m: 0.7557 - lr: 1.0000e-06\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "\n",
        "\n",
        "\n",
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
        "    return x, y\n",
        "\n",
        "def shuffling(x, y):\n",
        "    x, y = shuffle(x, y, random_state=42)\n",
        "    return x, y\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY);\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=-1)  \n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=-1)              ## (512, 512, 1)\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 1])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(X, Y, batch_size=2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(4)\n",
        "    return dataset\n",
        "\n",
        "def main():\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \n",
        "    create_dir(\"files\")\n",
        "\n",
        "\n",
        "    batch_size = 2\n",
        "    lr = 1e-4\n",
        "    num_epochs = 100\n",
        "    model_path = os.path.join(\"files\", \"model.h5\")\n",
        "    csv_path = os.path.join(\"files\", \"data.csv\")\n",
        "\n",
        "    #loading the dataset\n",
        "    dataset_path = \"new_data\"\n",
        "    train_path = os.path.join(dataset_path, \"train\")\n",
        "    valid_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "    train_x, train_y = load_data(train_path)\n",
        "    train_x, train_y = shuffling(train_x, train_y)\n",
        "    valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "    train_steps = len(train_x)//batch_size\n",
        "    valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "    if len(train_x) % batch_size != 0:\n",
        "        train_steps += 1\n",
        "    if len(valid_x) % batch_size != 0:\n",
        "        valid_setps += 1\n",
        "\n",
        "    \n",
        "    model = build_unet((H, W, 1))\n",
        "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[cross_loss, dice_coef, iou,f1_m,precision_m, recall_m])\n",
        "    # model.summary()\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        TensorBoard(),\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
        "    ]\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=valid_dataset,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_setps,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43hSmV0IVroj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH5Az3_wVien",
        "outputId": "7926b17c-12fe-4a8c-b2f5-18b163ced6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.63842\n",
            "F1: 0.61227\n",
            "Jaccard: 0.64270\n",
            "Recall: 0.64329\n",
            "Precision: 0.63243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY);\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return ori_x, x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (256, 256)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.int32)\n",
        "    return ori_x, x\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
        "    return x, y\n",
        "def save_results(ori_x, ori_y, y_pred, save_image_path):\n",
        "    \n",
        "    \n",
        "    ori_y = np.expand_dims(ori_y, axis=-1)\n",
        "    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)\n",
        "    \n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)*255\n",
        "    #y_pred = np.column_stack([y_pred, y_pred, y_pred]) *255\n",
        "   \n",
        "    #cat_images = np.column_stack([ori_x, ori_y, y_pred]) \n",
        "    cv2.imwrite(save_image_path, y_pred)\n",
        "\n",
        "def main():\n",
        "    create_dir(\"results\")\n",
        "\n",
        " \n",
        "    with CustomObjectScope({'cross_loss' : cross_loss, 'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss,'f1_m': f1_m, 'precision_m': precision_m,'recall_m':recall_m}):\n",
        "        model = tf.keras.models.load_model(\"files/model.h5\")\n",
        "\n",
        "    dataset_path = os.path.join(\"new_data\", \"test\")\n",
        "    test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "    SCORE = []\n",
        "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "      \n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        \n",
        "        ori_x, x = read_image(x)\n",
        "        ori_y, y = read_mask(y)\n",
        "      \n",
        "\n",
        "        \n",
        "\n",
        "        #prediction\n",
        "        y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "        y_pred = y_pred > 0.5\n",
        "        y_pred = y_pred.astype(np.int32)\n",
        "        y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "      \n",
        "        save_image_path = f\"results/{name}.png\"\n",
        "        save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "        #flattening the array\n",
        "        y = y.flatten()\n",
        "        y_pred = y_pred.flatten()\n",
        "\n",
        "        #metrics\n",
        "        acc_value = accuracy_score(y, y_pred)\n",
        "        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "    score = [s[1:] for s in SCORE]\n",
        "    score = np.mean(score, axis=-1)\n",
        "    print(f\"Accuracy: {score[1]:0.5f}\")\n",
        "    print(f\"F1: {score[2]:0.5f}\")\n",
        "    print(f\"Jaccard: {score[3]:0.5f}\")\n",
        "    print(f\"Recall: {score[4]:0.5f}\")\n",
        "    print(f\"Precision: {score[5]:0.5f}\")\n",
        "\n",
        "    df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "    df.to_csv(\"files/score.csv\")\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "   \n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "1HdKVHUK-BT_",
        "outputId": "8f3bc831-c632-42e5-afcc-542e2867174a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nlines = data_csv.plot.line(x='epoch', y=['precision_1', 'val_precision_1'])\\nplt.title('Precision Curves U-Net')\\nplt.ylabel('Precision')\\nplt.xlabel('Epoch')\\nplt.legend(['Training', 'Validation'], loc='lower right')\\nplt.show()\\n\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#accuracy dice coefficient precision graphs\n",
        "import io\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "path = \"/content/drive/MyDrive/DRIVE_Data/files/data.csv\"\n",
        "data_csv = pd.read_csv(path)\n",
        "#data_csv\n",
        "\n",
        "#shows how the val_loss decreases with each epoch\n",
        "\n",
        "lines = data_csv.plot.line(x='epoch', y=['loss', 'val_loss'])\n",
        "plt.title('Accuracy Curves U-Net')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "lines = data_csv.plot.line(x='epoch', y=['dice_coef', 'val_dice_coef'])\n",
        "plt.title('Dice Coefficient Curves U-Net')\n",
        "plt.ylabel('Dice Coefficient')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "'''\n",
        "lines = data_csv.plot.line(x='epoch', y=['precision_1', 'val_precision_1'])\n",
        "plt.title('Precision Curves U-Net')\n",
        "plt.ylabel('Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "fundus_imaging_unet (1).ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}