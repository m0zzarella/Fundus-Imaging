{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m0zzarella/Fundus-Imaging/blob/main/fundus_imaging_unet_exp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlEoTwcz_f-O",
        "outputId": "8cde3f46-3d93-4de0-bb0c-9d168d75aad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.21.6)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.6.0.66)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (4.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "!pip install albumentations\n",
        "from albumentations import HorizontalFlip, VerticalFlip, ElasticTransform, GridDistortion, OpticalDistortion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4u-nyo5QZhm",
        "outputId": "54eb7b78-4a94-47b5-b37b-866ebe158664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqVR4TWCQh1m",
        "outputId": "caa13c92-f05d-4a7a-d134-e53ca6501760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DRIVE_Data\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/DRIVE_Data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gthx41ggAg5E",
        "outputId": "3db5ffda-85e9-4df6-d249-23906d44e98f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 20 - 20\n",
            "Test: 20 - 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:11<00:00,  3.57s/it]\n",
            "100%|██████████| 20/20 [00:26<00:00,  1.34s/it]\n"
          ]
        }
      ],
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path):\n",
        "    train_x = sorted(glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))   #loading the images\n",
        "    train_y = sorted(glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))  #loading the masks\n",
        "\n",
        "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.tif\")))\n",
        "    test_y = sorted(glob(os.path.join(path, \"test\", \"1st_manual\", \"*.gif\")))\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "def augment_data(images, masks, save_path, augment=True):\n",
        "    H = 512\n",
        "    W = 512\n",
        "\n",
        "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
        "        \n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]    #extracts the images\n",
        "        \n",
        "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "        x = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY);\n",
        "        #kernel = np.ones((5,5), np.uint8)\n",
        "        #x = cv2.dilate(x, kernel, iterations=1)\n",
        "         \n",
        "        y = imageio.mimread(y)[0]\n",
        "\n",
        "        if augment == True:\n",
        "            aug = HorizontalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x1 = augmented[\"image\"]\n",
        "            y1 = augmented[\"mask\"]\n",
        "\n",
        "            aug = VerticalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x2 = augmented[\"image\"]\n",
        "            y2 = augmented[\"mask\"]\n",
        "\n",
        "            aug = ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x3 = augmented['image']\n",
        "            y3 = augmented['mask']\n",
        "\n",
        "            aug = GridDistortion(p=1)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x4 = augmented['image']\n",
        "            y4 = augmented['mask']\n",
        "\n",
        "            aug = OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x5 = augmented['image']\n",
        "            y5 = augmented['mask']\n",
        "\n",
        "            X = [x, x1, x2, x3, x4, x5]\n",
        "            Y = [y, y1, y2, y3, y4, y5]\n",
        "\n",
        "        else:\n",
        "            X = [x]\n",
        "            Y = [y]\n",
        "\n",
        "        index = 0\n",
        "        for i, m in zip(X, Y):\n",
        "            i = cv2.resize(i, (W, H))\n",
        "            m = cv2.resize(m, (W, H))\n",
        "\n",
        "            if len(X) == 1:\n",
        "                tmp_image_name = f\"{name}.jpg\"\n",
        "                tmp_mask_name = f\"{name}.jpg\"\n",
        "            else:\n",
        "                tmp_image_name = f\"{name}_{index}.jpg\"\n",
        "                tmp_mask_name = f\"{name}_{index}.jpg\"\n",
        "\n",
        "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
        "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
        "\n",
        "            cv2.imwrite(image_path, i)\n",
        "            cv2.imwrite(mask_path, m)\n",
        "\n",
        "            index += 1\n",
        "\n",
        "def main():\n",
        "    np.random.seed(42)  #saves the seed data to reproduce the results \n",
        "\n",
        "    data_path = \"/content/drive/MyDrive/DRIVE_Data\"\n",
        "    (train_x, train_y), (test_x, test_y) = load_data(data_path)\n",
        "\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "    print(f\"Test: {len(test_x)} - {len(test_y)}\")\n",
        "\n",
        "   \n",
        "    create_dir(\"new_data/train/image\")\n",
        "    create_dir(\"new_data/train/mask\")\n",
        "    create_dir(\"new_data/test/image\")\n",
        "    create_dir(\"new_data/test/mask\")\n",
        "\n",
        "    augment_data(train_x, train_y, \"new_data/train/\", augment=True)\n",
        "    augment_data(test_x, test_y, \"new_data/test/\", augment=False)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EAOY0m-aRmHM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import math\n",
        "\n",
        "#defining the loss functions\n",
        "def iou(y_true, y_pred):  #defining intersection over union\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def cross_entropy(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    return bce(y_true, y_pred)\n",
        "\n",
        "\n",
        "def cross_loss(y_true, y_pred):\n",
        "    return 1.0 - cross_entropy(y_true, y_pred)\n",
        "    \n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LSA1ATlRvxq",
        "outputId": "2f3dd496-db28-4426-9df2-6fa1f463917d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, 512, 512, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 512, 512, 32  320         ['input_9[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 512, 512, 32  128        ['conv2d_106[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 512, 512, 32  0           ['batch_normalization_104[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 512, 512, 32  9248        ['activation_104[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 512, 512, 32  128        ['conv2d_107[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 512, 512, 32  0           ['batch_normalization_105[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_31 (MaxPooling2D  (None, 256, 256, 32  0          ['activation_105[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 256, 256, 64  18496       ['max_pooling2d_31[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 256, 256, 64  256        ['conv2d_108[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_106[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 256, 256, 64  36928       ['activation_106[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 256, 256, 64  256        ['conv2d_109[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_107[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_32 (MaxPooling2D  (None, 128, 128, 64  0          ['activation_107[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_32[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " dropout_30 (Dropout)           (None, 128, 128, 12  0           ['conv2d_110[0][0]']             \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 128, 128, 12  512        ['dropout_30[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_108[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 128, 128, 12  147584      ['activation_108[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 128, 128, 12  512        ['conv2d_111[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_109[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_33 (MaxPooling2D  (None, 64, 64, 128)  0          ['activation_109[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_33[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_31 (Dropout)           (None, 64, 64, 256)  0           ['conv2d_112[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 64, 64, 256)  1024       ['dropout_31[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 64, 64, 256)  590080      ['activation_110[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 64, 64, 256)  1024       ['conv2d_113[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_34 (MaxPooling2D  (None, 32, 32, 256)  0          ['activation_111[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_34[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_32 (Dropout)           (None, 32, 32, 512)  0           ['conv2d_114[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 32, 32, 512)  2048       ['dropout_32[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 32, 32, 512)  2359808     ['activation_112[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 32, 32, 512)  2048       ['conv2d_115[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_113[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_19 (Conv2DTra  (None, 64, 64, 256)  524544     ['activation_113[0][0]']         \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_transpose_19[0][0]',    \n",
            "                                                                  'activation_111[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 64, 64, 256)  1179904     ['concatenate_19[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_33 (Dropout)           (None, 64, 64, 256)  0           ['conv2d_116[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 64, 64, 256)  1024       ['dropout_33[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 64, 64, 256)  590080      ['activation_114[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 64, 64, 256)  1024       ['conv2d_117[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_transpose_20 (Conv2DTra  (None, 128, 128, 12  131200     ['activation_115[0][0]']         \n",
            " nspose)                        8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_transpose_20[0][0]',    \n",
            "                                6)                                'activation_109[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 128, 128, 12  295040      ['concatenate_20[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " dropout_34 (Dropout)           (None, 128, 128, 12  0           ['conv2d_118[0][0]']             \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 128, 128, 12  512        ['dropout_34[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_116[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 128, 128, 12  147584      ['activation_116[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 128, 128, 12  512        ['conv2d_119[0][0]']             \n",
            " Normalization)                 8)                                                                \n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_117[0][0]']\n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_21 (Conv2DTra  (None, 256, 256, 64  32832      ['activation_117[0][0]']         \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_transpose_21[0][0]',    \n",
            "                                8)                                'activation_107[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_21[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 256, 256, 64  256        ['conv2d_120[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_118[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 256, 256, 64  36928       ['activation_118[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_119 (Batch  (None, 256, 256, 64  256        ['conv2d_121[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_119 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_119[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_22 (Conv2DTra  (None, 512, 512, 32  8224       ['activation_119[0][0]']         \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenate)   (None, 512, 512, 64  0           ['conv2d_transpose_22[0][0]',    \n",
            "                                )                                 'activation_105[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 512, 512, 32  18464       ['concatenate_22[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_120 (Batch  (None, 512, 512, 32  128        ['conv2d_122[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_120 (Activation)    (None, 512, 512, 32  0           ['batch_normalization_120[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 512, 512, 32  9248        ['activation_120[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_121 (Batch  (None, 512, 512, 32  128        ['conv2d_123[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " activation_121 (Activation)    (None, 512, 512, 32  0           ['batch_normalization_121[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 512, 512, 1)  33          ['activation_121[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,771,297\n",
            "Trainable params: 7,765,409\n",
            "Non-trainable params: 5,888\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#defining the u-net monte carlo dropout model\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout, MaxPooling2D\n",
        "from keras.models import Model\n",
        "\n",
        "drop_rate = 0.5\n",
        "drop_train = False #monte carlo dropout\n",
        "#drop_train = True\n",
        "\n",
        "def conv_block(inputs, num_filters):\n",
        "    \n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def conv_dropout(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = Dropout(drop_rate)(x, training = drop_train)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def encoder_dropout(inputs, num_filters):\n",
        "    x = conv_dropout(inputs, num_filters)\n",
        "    p = MaxPooling2D((2, 2))(x)\n",
        "    return x, p\n",
        "  \n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def decoder_dropout(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_dropout(x, num_filters)\n",
        "    return x\n",
        "   \n",
        "\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    e1, p1 = encoder_block(inputs, 32)\n",
        "    e2, p2 = encoder_block(p1, 64)\n",
        "    e3, p3 = encoder_dropout(p2, 128)\n",
        "    e4, p4 = encoder_dropout(p3, 256)\n",
        "\n",
        "    base1 = conv_dropout(p4, 512)\n",
        "\n",
        "    d1 = decoder_dropout(base1, e4, 256)\n",
        "    d2 = decoder_dropout(d1, e3, 128)\n",
        "    d3 = decoder_block(d2, e2, 64)\n",
        "    d4 = decoder_block(d3, e1, 32)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    input_shape = (512, 512, 1)\n",
        "    model = build_unet(input_shape)\n",
        "    model.summary()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0o_WrwNRyH2",
        "outputId": "0a8eddb1-f41e-49f4-e900-8425bf67ce26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 120 - 120\n",
            "Valid: 20 - 20\n",
            "Epoch 1/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.7186 - cross_loss: 0.1353 - dice_coef: 0.2814 - iou: 0.1652 - f1_m: 0.3170 - precision_m: 0.2037 - recall_m: 0.8018\n",
            "Epoch 1: val_loss improved from inf to 0.85170, saving model to files/model.h5\n",
            "60/60 [==============================] - 32s 231ms/step - loss: 0.7186 - cross_loss: 0.1353 - dice_coef: 0.2814 - iou: 0.1652 - f1_m: 0.3170 - precision_m: 0.2037 - recall_m: 0.8018 - val_loss: 0.8517 - val_cross_loss: 0.0737 - val_dice_coef: 0.1483 - val_iou: 0.0801 - val_f1_m: 0.0035 - val_precision_m: 0.0024 - val_recall_m: 0.0062 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6015 - cross_loss: 0.2178 - dice_coef: 0.3985 - iou: 0.2493 - f1_m: 0.5495 - precision_m: 0.4160 - recall_m: 0.8204\n",
            "Epoch 2: val_loss did not improve from 0.85170\n",
            "60/60 [==============================] - 11s 187ms/step - loss: 0.6015 - cross_loss: 0.2178 - dice_coef: 0.3985 - iou: 0.2493 - f1_m: 0.5495 - precision_m: 0.4160 - recall_m: 0.8204 - val_loss: 0.8628 - val_cross_loss: 0.1378 - val_dice_coef: 0.1372 - val_iou: 0.0737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5602 - cross_loss: 0.2392 - dice_coef: 0.4398 - iou: 0.2823 - f1_m: 0.6141 - precision_m: 0.4938 - recall_m: 0.8192\n",
            "Epoch 3: val_loss did not improve from 0.85170\n",
            "60/60 [==============================] - 11s 185ms/step - loss: 0.5602 - cross_loss: 0.2392 - dice_coef: 0.4398 - iou: 0.2823 - f1_m: 0.6141 - precision_m: 0.4938 - recall_m: 0.8192 - val_loss: 0.8754 - val_cross_loss: 0.1894 - val_dice_coef: 0.1246 - val_iou: 0.0664 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5325 - cross_loss: 0.2503 - dice_coef: 0.4675 - iou: 0.3056 - f1_m: 0.6489 - precision_m: 0.5372 - recall_m: 0.8253\n",
            "Epoch 4: val_loss did not improve from 0.85170\n",
            "60/60 [==============================] - 11s 189ms/step - loss: 0.5325 - cross_loss: 0.2503 - dice_coef: 0.4675 - iou: 0.3056 - f1_m: 0.6489 - precision_m: 0.5372 - recall_m: 0.8253 - val_loss: 0.8870 - val_cross_loss: 0.2216 - val_dice_coef: 0.1130 - val_iou: 0.0599 - val_f1_m: 0.0015 - val_precision_m: 0.0127 - val_recall_m: 7.9178e-04 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5093 - cross_loss: 0.2587 - dice_coef: 0.4907 - iou: 0.3257 - f1_m: 0.6728 - precision_m: 0.5687 - recall_m: 0.8291\n",
            "Epoch 5: val_loss did not improve from 0.85170\n",
            "60/60 [==============================] - 11s 187ms/step - loss: 0.5093 - cross_loss: 0.2587 - dice_coef: 0.4907 - iou: 0.3257 - f1_m: 0.6728 - precision_m: 0.5687 - recall_m: 0.8291 - val_loss: 0.8912 - val_cross_loss: 0.2357 - val_dice_coef: 0.1088 - val_iou: 0.0575 - val_f1_m: 0.0384 - val_precision_m: 0.0878 - val_recall_m: 0.0247 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4867 - cross_loss: 0.2660 - dice_coef: 0.5133 - iou: 0.3458 - f1_m: 0.6940 - precision_m: 0.5966 - recall_m: 0.8345\n",
            "Epoch 6: val_loss improved from 0.85170 to 0.82381, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 208ms/step - loss: 0.4867 - cross_loss: 0.2660 - dice_coef: 0.5133 - iou: 0.3458 - f1_m: 0.6940 - precision_m: 0.5966 - recall_m: 0.8345 - val_loss: 0.8238 - val_cross_loss: 0.2462 - val_dice_coef: 0.1762 - val_iou: 0.0968 - val_f1_m: 0.1856 - val_precision_m: 0.2642 - val_recall_m: 0.1433 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4655 - cross_loss: 0.2722 - dice_coef: 0.5345 - iou: 0.3653 - f1_m: 0.7117 - precision_m: 0.6206 - recall_m: 0.8388\n",
            "Epoch 7: val_loss improved from 0.82381 to 0.69061, saving model to files/model.h5\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.4655 - cross_loss: 0.2722 - dice_coef: 0.5345 - iou: 0.3653 - f1_m: 0.7117 - precision_m: 0.6206 - recall_m: 0.8388 - val_loss: 0.6906 - val_cross_loss: 0.2576 - val_dice_coef: 0.3094 - val_iou: 0.1833 - val_f1_m: 0.4091 - val_precision_m: 0.4557 - val_recall_m: 0.3721 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4462 - cross_loss: 0.2775 - dice_coef: 0.5538 - iou: 0.3836 - f1_m: 0.7252 - precision_m: 0.6390 - recall_m: 0.8424\n",
            "Epoch 8: val_loss improved from 0.69061 to 0.61094, saving model to files/model.h5\n",
            "60/60 [==============================] - 12s 205ms/step - loss: 0.4462 - cross_loss: 0.2775 - dice_coef: 0.5538 - iou: 0.3836 - f1_m: 0.7252 - precision_m: 0.6390 - recall_m: 0.8424 - val_loss: 0.6109 - val_cross_loss: 0.2650 - val_dice_coef: 0.3891 - val_iou: 0.2419 - val_f1_m: 0.5475 - val_precision_m: 0.5857 - val_recall_m: 0.5153 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4289 - cross_loss: 0.2821 - dice_coef: 0.5711 - iou: 0.4002 - f1_m: 0.7354 - precision_m: 0.6548 - recall_m: 0.8426\n",
            "Epoch 9: val_loss improved from 0.61094 to 0.52884, saving model to files/model.h5\n",
            "60/60 [==============================] - 12s 207ms/step - loss: 0.4289 - cross_loss: 0.2821 - dice_coef: 0.5711 - iou: 0.4002 - f1_m: 0.7354 - precision_m: 0.6548 - recall_m: 0.8426 - val_loss: 0.5288 - val_cross_loss: 0.2768 - val_dice_coef: 0.4712 - val_iou: 0.3086 - val_f1_m: 0.6477 - val_precision_m: 0.6671 - val_recall_m: 0.6323 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4118 - cross_loss: 0.2862 - dice_coef: 0.5882 - iou: 0.4172 - f1_m: 0.7449 - precision_m: 0.6687 - recall_m: 0.8445\n",
            "Epoch 10: val_loss improved from 0.52884 to 0.46559, saving model to files/model.h5\n",
            "60/60 [==============================] - 12s 200ms/step - loss: 0.4118 - cross_loss: 0.2862 - dice_coef: 0.5882 - iou: 0.4172 - f1_m: 0.7449 - precision_m: 0.6687 - recall_m: 0.8445 - val_loss: 0.4656 - val_cross_loss: 0.2866 - val_dice_coef: 0.5344 - val_iou: 0.3652 - val_f1_m: 0.7083 - val_precision_m: 0.7247 - val_recall_m: 0.6981 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3948 - cross_loss: 0.2900 - dice_coef: 0.6052 - iou: 0.4345 - f1_m: 0.7550 - precision_m: 0.6832 - recall_m: 0.8471\n",
            "Epoch 11: val_loss improved from 0.46559 to 0.44625, saving model to files/model.h5\n",
            "60/60 [==============================] - 12s 205ms/step - loss: 0.3948 - cross_loss: 0.2900 - dice_coef: 0.6052 - iou: 0.4345 - f1_m: 0.7550 - precision_m: 0.6832 - recall_m: 0.8471 - val_loss: 0.4462 - val_cross_loss: 0.2927 - val_dice_coef: 0.5538 - val_iou: 0.3833 - val_f1_m: 0.7237 - val_precision_m: 0.7757 - val_recall_m: 0.6819 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3797 - cross_loss: 0.2933 - dice_coef: 0.6203 - iou: 0.4502 - f1_m: 0.7627 - precision_m: 0.6955 - recall_m: 0.8476\n",
            "Epoch 12: val_loss improved from 0.44625 to 0.41299, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 211ms/step - loss: 0.3797 - cross_loss: 0.2933 - dice_coef: 0.6203 - iou: 0.4502 - f1_m: 0.7627 - precision_m: 0.6955 - recall_m: 0.8476 - val_loss: 0.4130 - val_cross_loss: 0.2941 - val_dice_coef: 0.5870 - val_iou: 0.4157 - val_f1_m: 0.7377 - val_precision_m: 0.7335 - val_recall_m: 0.7454 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3658 - cross_loss: 0.2963 - dice_coef: 0.6342 - iou: 0.4649 - f1_m: 0.7694 - precision_m: 0.7074 - recall_m: 0.8464\n",
            "Epoch 13: val_loss improved from 0.41299 to 0.39823, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 209ms/step - loss: 0.3658 - cross_loss: 0.2963 - dice_coef: 0.6342 - iou: 0.4649 - f1_m: 0.7694 - precision_m: 0.7074 - recall_m: 0.8464 - val_loss: 0.3982 - val_cross_loss: 0.2958 - val_dice_coef: 0.6018 - val_iou: 0.4305 - val_f1_m: 0.7524 - val_precision_m: 0.7442 - val_recall_m: 0.7637 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3501 - cross_loss: 0.2992 - dice_coef: 0.6499 - iou: 0.4820 - f1_m: 0.7786 - precision_m: 0.7208 - recall_m: 0.8495\n",
            "Epoch 14: val_loss improved from 0.39823 to 0.39557, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 211ms/step - loss: 0.3501 - cross_loss: 0.2992 - dice_coef: 0.6499 - iou: 0.4820 - f1_m: 0.7786 - precision_m: 0.7208 - recall_m: 0.8495 - val_loss: 0.3956 - val_cross_loss: 0.2987 - val_dice_coef: 0.6044 - val_iou: 0.4333 - val_f1_m: 0.7478 - val_precision_m: 0.7656 - val_recall_m: 0.7337 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3369 - cross_loss: 0.3017 - dice_coef: 0.6631 - iou: 0.4966 - f1_m: 0.7852 - precision_m: 0.7310 - recall_m: 0.8507\n",
            "Epoch 15: val_loss improved from 0.39557 to 0.38040, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 212ms/step - loss: 0.3369 - cross_loss: 0.3017 - dice_coef: 0.6631 - iou: 0.4966 - f1_m: 0.7852 - precision_m: 0.7310 - recall_m: 0.8507 - val_loss: 0.3804 - val_cross_loss: 0.2990 - val_dice_coef: 0.6196 - val_iou: 0.4491 - val_f1_m: 0.7526 - val_precision_m: 0.7429 - val_recall_m: 0.7661 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3264 - cross_loss: 0.3036 - dice_coef: 0.6736 - iou: 0.5084 - f1_m: 0.7887 - precision_m: 0.7378 - recall_m: 0.8503\n",
            "Epoch 16: val_loss improved from 0.38040 to 0.36606, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.3264 - cross_loss: 0.3036 - dice_coef: 0.6736 - iou: 0.5084 - f1_m: 0.7887 - precision_m: 0.7378 - recall_m: 0.8503 - val_loss: 0.3661 - val_cross_loss: 0.3023 - val_dice_coef: 0.6339 - val_iou: 0.4642 - val_f1_m: 0.7531 - val_precision_m: 0.7536 - val_recall_m: 0.7558 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3165 - cross_loss: 0.3054 - dice_coef: 0.6835 - iou: 0.5198 - f1_m: 0.7916 - precision_m: 0.7431 - recall_m: 0.8497\n",
            "Epoch 17: val_loss improved from 0.36606 to 0.35777, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.3165 - cross_loss: 0.3054 - dice_coef: 0.6835 - iou: 0.5198 - f1_m: 0.7916 - precision_m: 0.7431 - recall_m: 0.8497 - val_loss: 0.3578 - val_cross_loss: 0.3044 - val_dice_coef: 0.6422 - val_iou: 0.4731 - val_f1_m: 0.7519 - val_precision_m: 0.7602 - val_recall_m: 0.7471 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3047 - cross_loss: 0.3074 - dice_coef: 0.6953 - iou: 0.5335 - f1_m: 0.7986 - precision_m: 0.7542 - recall_m: 0.8510\n",
            "Epoch 18: val_loss improved from 0.35777 to 0.34152, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.3047 - cross_loss: 0.3074 - dice_coef: 0.6953 - iou: 0.5335 - f1_m: 0.7986 - precision_m: 0.7542 - recall_m: 0.8510 - val_loss: 0.3415 - val_cross_loss: 0.3062 - val_dice_coef: 0.6585 - val_iou: 0.4910 - val_f1_m: 0.7575 - val_precision_m: 0.7584 - val_recall_m: 0.7596 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2936 - cross_loss: 0.3092 - dice_coef: 0.7064 - iou: 0.5466 - f1_m: 0.8049 - precision_m: 0.7640 - recall_m: 0.8527\n",
            "Epoch 19: val_loss improved from 0.34152 to 0.33262, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 214ms/step - loss: 0.2936 - cross_loss: 0.3092 - dice_coef: 0.7064 - iou: 0.5466 - f1_m: 0.8049 - precision_m: 0.7640 - recall_m: 0.8527 - val_loss: 0.3326 - val_cross_loss: 0.3062 - val_dice_coef: 0.6674 - val_iou: 0.5009 - val_f1_m: 0.7596 - val_precision_m: 0.7426 - val_recall_m: 0.7806 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2850 - cross_loss: 0.3104 - dice_coef: 0.7150 - iou: 0.5569 - f1_m: 0.8082 - precision_m: 0.7685 - recall_m: 0.8543\n",
            "Epoch 20: val_loss improved from 0.33262 to 0.33136, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2850 - cross_loss: 0.3104 - dice_coef: 0.7150 - iou: 0.5569 - f1_m: 0.8082 - precision_m: 0.7685 - recall_m: 0.8543 - val_loss: 0.3314 - val_cross_loss: 0.3071 - val_dice_coef: 0.6686 - val_iou: 0.5024 - val_f1_m: 0.7568 - val_precision_m: 0.7468 - val_recall_m: 0.7699 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2780 - cross_loss: 0.3116 - dice_coef: 0.7220 - iou: 0.5655 - f1_m: 0.8099 - precision_m: 0.7724 - recall_m: 0.8535\n",
            "Epoch 21: val_loss improved from 0.33136 to 0.32925, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.2780 - cross_loss: 0.3116 - dice_coef: 0.7220 - iou: 0.5655 - f1_m: 0.8099 - precision_m: 0.7724 - recall_m: 0.8535 - val_loss: 0.3292 - val_cross_loss: 0.3091 - val_dice_coef: 0.6708 - val_iou: 0.5047 - val_f1_m: 0.7533 - val_precision_m: 0.7657 - val_recall_m: 0.7440 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2720 - cross_loss: 0.3125 - dice_coef: 0.7280 - iou: 0.5729 - f1_m: 0.8110 - precision_m: 0.7754 - recall_m: 0.8522\n",
            "Epoch 22: val_loss improved from 0.32925 to 0.32643, saving model to files/model.h5\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.2720 - cross_loss: 0.3125 - dice_coef: 0.7280 - iou: 0.5729 - f1_m: 0.8110 - precision_m: 0.7754 - recall_m: 0.8522 - val_loss: 0.3264 - val_cross_loss: 0.3104 - val_dice_coef: 0.6736 - val_iou: 0.5080 - val_f1_m: 0.7523 - val_precision_m: 0.7784 - val_recall_m: 0.7308 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2665 - cross_loss: 0.3134 - dice_coef: 0.7335 - iou: 0.5797 - f1_m: 0.8121 - precision_m: 0.7786 - recall_m: 0.8508\n",
            "Epoch 23: val_loss improved from 0.32643 to 0.32212, saving model to files/model.h5\n",
            "60/60 [==============================] - 12s 208ms/step - loss: 0.2665 - cross_loss: 0.3134 - dice_coef: 0.7335 - iou: 0.5797 - f1_m: 0.8121 - precision_m: 0.7786 - recall_m: 0.8508 - val_loss: 0.3221 - val_cross_loss: 0.3101 - val_dice_coef: 0.6779 - val_iou: 0.5129 - val_f1_m: 0.7572 - val_precision_m: 0.7710 - val_recall_m: 0.7467 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2603 - cross_loss: 0.3143 - dice_coef: 0.7397 - iou: 0.5875 - f1_m: 0.8143 - precision_m: 0.7822 - recall_m: 0.8512\n",
            "Epoch 24: val_loss did not improve from 0.32212\n",
            "60/60 [==============================] - 12s 198ms/step - loss: 0.2603 - cross_loss: 0.3143 - dice_coef: 0.7397 - iou: 0.5875 - f1_m: 0.8143 - precision_m: 0.7822 - recall_m: 0.8512 - val_loss: 0.3481 - val_cross_loss: 0.3118 - val_dice_coef: 0.6519 - val_iou: 0.4841 - val_f1_m: 0.7238 - val_precision_m: 0.8071 - val_recall_m: 0.6600 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2509 - cross_loss: 0.3155 - dice_coef: 0.7491 - iou: 0.5994 - f1_m: 0.8210 - precision_m: 0.7901 - recall_m: 0.8566\n",
            "Epoch 25: val_loss did not improve from 0.32212\n",
            "60/60 [==============================] - 12s 198ms/step - loss: 0.2509 - cross_loss: 0.3155 - dice_coef: 0.7491 - iou: 0.5994 - f1_m: 0.8210 - precision_m: 0.7901 - recall_m: 0.8566 - val_loss: 0.3312 - val_cross_loss: 0.3121 - val_dice_coef: 0.6688 - val_iou: 0.5027 - val_f1_m: 0.7385 - val_precision_m: 0.7946 - val_recall_m: 0.6924 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2432 - cross_loss: 0.3166 - dice_coef: 0.7568 - iou: 0.6093 - f1_m: 0.8264 - precision_m: 0.7986 - recall_m: 0.8582\n",
            "Epoch 26: val_loss improved from 0.32212 to 0.31482, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.2432 - cross_loss: 0.3166 - dice_coef: 0.7568 - iou: 0.6093 - f1_m: 0.8264 - precision_m: 0.7986 - recall_m: 0.8582 - val_loss: 0.3148 - val_cross_loss: 0.3129 - val_dice_coef: 0.6852 - val_iou: 0.5213 - val_f1_m: 0.7518 - val_precision_m: 0.7917 - val_recall_m: 0.7183 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2385 - cross_loss: 0.3173 - dice_coef: 0.7615 - iou: 0.6153 - f1_m: 0.8278 - precision_m: 0.8016 - recall_m: 0.8574\n",
            "Epoch 27: val_loss improved from 0.31482 to 0.30697, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.2385 - cross_loss: 0.3173 - dice_coef: 0.7615 - iou: 0.6153 - f1_m: 0.8278 - precision_m: 0.8016 - recall_m: 0.8574 - val_loss: 0.3070 - val_cross_loss: 0.3138 - val_dice_coef: 0.6930 - val_iou: 0.5304 - val_f1_m: 0.7567 - val_precision_m: 0.7960 - val_recall_m: 0.7237 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2359 - cross_loss: 0.3176 - dice_coef: 0.7641 - iou: 0.6188 - f1_m: 0.8272 - precision_m: 0.8016 - recall_m: 0.8561\n",
            "Epoch 28: val_loss did not improve from 0.30697\n",
            "60/60 [==============================] - 12s 199ms/step - loss: 0.2359 - cross_loss: 0.3176 - dice_coef: 0.7641 - iou: 0.6188 - f1_m: 0.8272 - precision_m: 0.8016 - recall_m: 0.8561 - val_loss: 0.3134 - val_cross_loss: 0.3140 - val_dice_coef: 0.6866 - val_iou: 0.5230 - val_f1_m: 0.7469 - val_precision_m: 0.7995 - val_recall_m: 0.7037 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2321 - cross_loss: 0.3182 - dice_coef: 0.7679 - iou: 0.6237 - f1_m: 0.8283 - precision_m: 0.8041 - recall_m: 0.8556\n",
            "Epoch 29: val_loss improved from 0.30697 to 0.30595, saving model to files/model.h5\n",
            "60/60 [==============================] - 14s 233ms/step - loss: 0.2321 - cross_loss: 0.3182 - dice_coef: 0.7679 - iou: 0.6237 - f1_m: 0.8283 - precision_m: 0.8041 - recall_m: 0.8556 - val_loss: 0.3059 - val_cross_loss: 0.3151 - val_dice_coef: 0.6941 - val_iou: 0.5317 - val_f1_m: 0.7503 - val_precision_m: 0.8073 - val_recall_m: 0.7036 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2267 - cross_loss: 0.3189 - dice_coef: 0.7733 - iou: 0.6309 - f1_m: 0.8317 - precision_m: 0.8087 - recall_m: 0.8576\n",
            "Epoch 30: val_loss improved from 0.30595 to 0.30406, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.2267 - cross_loss: 0.3189 - dice_coef: 0.7733 - iou: 0.6309 - f1_m: 0.8317 - precision_m: 0.8087 - recall_m: 0.8576 - val_loss: 0.3041 - val_cross_loss: 0.3152 - val_dice_coef: 0.6959 - val_iou: 0.5339 - val_f1_m: 0.7499 - val_precision_m: 0.8041 - val_recall_m: 0.7053 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2212 - cross_loss: 0.3195 - dice_coef: 0.7788 - iou: 0.6381 - f1_m: 0.8352 - precision_m: 0.8132 - recall_m: 0.8601\n",
            "Epoch 31: val_loss improved from 0.30406 to 0.30390, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.2212 - cross_loss: 0.3195 - dice_coef: 0.7788 - iou: 0.6381 - f1_m: 0.8352 - precision_m: 0.8132 - recall_m: 0.8601 - val_loss: 0.3039 - val_cross_loss: 0.3150 - val_dice_coef: 0.6961 - val_iou: 0.5341 - val_f1_m: 0.7478 - val_precision_m: 0.7945 - val_recall_m: 0.7089 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2184 - cross_loss: 0.3199 - dice_coef: 0.7816 - iou: 0.6420 - f1_m: 0.8359 - precision_m: 0.8146 - recall_m: 0.8597\n",
            "Epoch 32: val_loss improved from 0.30390 to 0.29860, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.2184 - cross_loss: 0.3199 - dice_coef: 0.7816 - iou: 0.6420 - f1_m: 0.8359 - precision_m: 0.8146 - recall_m: 0.8597 - val_loss: 0.2986 - val_cross_loss: 0.3164 - val_dice_coef: 0.7014 - val_iou: 0.5404 - val_f1_m: 0.7494 - val_precision_m: 0.8123 - val_recall_m: 0.6981 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2154 - cross_loss: 0.3203 - dice_coef: 0.7846 - iou: 0.6459 - f1_m: 0.8368 - precision_m: 0.8163 - recall_m: 0.8599\n",
            "Epoch 33: val_loss improved from 0.29860 to 0.29583, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 210ms/step - loss: 0.2154 - cross_loss: 0.3203 - dice_coef: 0.7846 - iou: 0.6459 - f1_m: 0.8368 - precision_m: 0.8163 - recall_m: 0.8599 - val_loss: 0.2958 - val_cross_loss: 0.3170 - val_dice_coef: 0.7042 - val_iou: 0.5438 - val_f1_m: 0.7493 - val_precision_m: 0.8168 - val_recall_m: 0.6949 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2101 - cross_loss: 0.3209 - dice_coef: 0.7899 - iou: 0.6532 - f1_m: 0.8408 - precision_m: 0.8215 - recall_m: 0.8625\n",
            "Epoch 34: val_loss improved from 0.29583 to 0.28475, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 216ms/step - loss: 0.2101 - cross_loss: 0.3209 - dice_coef: 0.7899 - iou: 0.6532 - f1_m: 0.8408 - precision_m: 0.8215 - recall_m: 0.8625 - val_loss: 0.2848 - val_cross_loss: 0.3165 - val_dice_coef: 0.7152 - val_iou: 0.5570 - val_f1_m: 0.7582 - val_precision_m: 0.7941 - val_recall_m: 0.7283 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2046 - cross_loss: 0.3215 - dice_coef: 0.7954 - iou: 0.6607 - f1_m: 0.8455 - precision_m: 0.8267 - recall_m: 0.8665\n",
            "Epoch 35: val_loss improved from 0.28475 to 0.27629, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 213ms/step - loss: 0.2046 - cross_loss: 0.3215 - dice_coef: 0.7954 - iou: 0.6607 - f1_m: 0.8455 - precision_m: 0.8267 - recall_m: 0.8665 - val_loss: 0.2763 - val_cross_loss: 0.3165 - val_dice_coef: 0.7237 - val_iou: 0.5672 - val_f1_m: 0.7669 - val_precision_m: 0.7895 - val_recall_m: 0.7484 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1987 - cross_loss: 0.3222 - dice_coef: 0.8013 - iou: 0.6688 - f1_m: 0.8510 - precision_m: 0.8336 - recall_m: 0.8703\n",
            "Epoch 36: val_loss did not improve from 0.27629\n",
            "60/60 [==============================] - 12s 198ms/step - loss: 0.1987 - cross_loss: 0.3222 - dice_coef: 0.8013 - iou: 0.6688 - f1_m: 0.8510 - precision_m: 0.8336 - recall_m: 0.8703 - val_loss: 0.2801 - val_cross_loss: 0.3161 - val_dice_coef: 0.7199 - val_iou: 0.5626 - val_f1_m: 0.7598 - val_precision_m: 0.7788 - val_recall_m: 0.7447 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1943 - cross_loss: 0.3227 - dice_coef: 0.8057 - iou: 0.6751 - f1_m: 0.8547 - precision_m: 0.8383 - recall_m: 0.8728\n",
            "Epoch 37: val_loss did not improve from 0.27629\n",
            "60/60 [==============================] - 12s 199ms/step - loss: 0.1943 - cross_loss: 0.3227 - dice_coef: 0.8057 - iou: 0.6751 - f1_m: 0.8547 - precision_m: 0.8383 - recall_m: 0.8728 - val_loss: 0.2790 - val_cross_loss: 0.3164 - val_dice_coef: 0.7210 - val_iou: 0.5639 - val_f1_m: 0.7591 - val_precision_m: 0.7815 - val_recall_m: 0.7409 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1923 - cross_loss: 0.3229 - dice_coef: 0.8077 - iou: 0.6779 - f1_m: 0.8553 - precision_m: 0.8395 - recall_m: 0.8727\n",
            "Epoch 38: val_loss did not improve from 0.27629\n",
            "60/60 [==============================] - 12s 200ms/step - loss: 0.1923 - cross_loss: 0.3229 - dice_coef: 0.8077 - iou: 0.6779 - f1_m: 0.8553 - precision_m: 0.8395 - recall_m: 0.8727 - val_loss: 0.2766 - val_cross_loss: 0.3181 - val_dice_coef: 0.7234 - val_iou: 0.5670 - val_f1_m: 0.7612 - val_precision_m: 0.8126 - val_recall_m: 0.7188 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1896 - cross_loss: 0.3232 - dice_coef: 0.8104 - iou: 0.6816 - f1_m: 0.8569 - precision_m: 0.8415 - recall_m: 0.8739\n",
            "Epoch 39: val_loss improved from 0.27629 to 0.27539, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1896 - cross_loss: 0.3232 - dice_coef: 0.8104 - iou: 0.6816 - f1_m: 0.8569 - precision_m: 0.8415 - recall_m: 0.8739 - val_loss: 0.2754 - val_cross_loss: 0.3185 - val_dice_coef: 0.7246 - val_iou: 0.5684 - val_f1_m: 0.7611 - val_precision_m: 0.8168 - val_recall_m: 0.7154 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1873 - cross_loss: 0.3235 - dice_coef: 0.8127 - iou: 0.6849 - f1_m: 0.8581 - precision_m: 0.8429 - recall_m: 0.8748\n",
            "Epoch 40: val_loss did not improve from 0.27539\n",
            "60/60 [==============================] - 12s 197ms/step - loss: 0.1873 - cross_loss: 0.3235 - dice_coef: 0.8127 - iou: 0.6849 - f1_m: 0.8581 - precision_m: 0.8429 - recall_m: 0.8748 - val_loss: 0.2801 - val_cross_loss: 0.3185 - val_dice_coef: 0.7199 - val_iou: 0.5627 - val_f1_m: 0.7544 - val_precision_m: 0.8183 - val_recall_m: 0.7028 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1858 - cross_loss: 0.3236 - dice_coef: 0.8142 - iou: 0.6870 - f1_m: 0.8586 - precision_m: 0.8440 - recall_m: 0.8749\n",
            "Epoch 41: val_loss did not improve from 0.27539\n",
            "60/60 [==============================] - 12s 199ms/step - loss: 0.1858 - cross_loss: 0.3236 - dice_coef: 0.8142 - iou: 0.6870 - f1_m: 0.8586 - precision_m: 0.8440 - recall_m: 0.8749 - val_loss: 0.2915 - val_cross_loss: 0.3184 - val_dice_coef: 0.7085 - val_iou: 0.5491 - val_f1_m: 0.7413 - val_precision_m: 0.8229 - val_recall_m: 0.6775 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1837 - cross_loss: 0.3239 - dice_coef: 0.8163 - iou: 0.6900 - f1_m: 0.8600 - precision_m: 0.8465 - recall_m: 0.8749\n",
            "Epoch 42: val_loss did not improve from 0.27539\n",
            "60/60 [==============================] - 12s 199ms/step - loss: 0.1837 - cross_loss: 0.3239 - dice_coef: 0.8163 - iou: 0.6900 - f1_m: 0.8600 - precision_m: 0.8465 - recall_m: 0.8749 - val_loss: 0.2794 - val_cross_loss: 0.3170 - val_dice_coef: 0.7206 - val_iou: 0.5634 - val_f1_m: 0.7508 - val_precision_m: 0.7793 - val_recall_m: 0.7275 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1831 - cross_loss: 0.3240 - dice_coef: 0.8169 - iou: 0.6910 - f1_m: 0.8593 - precision_m: 0.8457 - recall_m: 0.8742\n",
            "Epoch 43: val_loss improved from 0.27539 to 0.27074, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1831 - cross_loss: 0.3240 - dice_coef: 0.8169 - iou: 0.6910 - f1_m: 0.8593 - precision_m: 0.8457 - recall_m: 0.8742 - val_loss: 0.2707 - val_cross_loss: 0.3182 - val_dice_coef: 0.7293 - val_iou: 0.5741 - val_f1_m: 0.7602 - val_precision_m: 0.7977 - val_recall_m: 0.7290 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1835 - cross_loss: 0.3240 - dice_coef: 0.8165 - iou: 0.6903 - f1_m: 0.8575 - precision_m: 0.8440 - recall_m: 0.8723\n",
            "Epoch 44: val_loss improved from 0.27074 to 0.26358, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 215ms/step - loss: 0.1835 - cross_loss: 0.3240 - dice_coef: 0.8165 - iou: 0.6903 - f1_m: 0.8575 - precision_m: 0.8440 - recall_m: 0.8723 - val_loss: 0.2636 - val_cross_loss: 0.3179 - val_dice_coef: 0.7364 - val_iou: 0.5830 - val_f1_m: 0.7669 - val_precision_m: 0.7860 - val_recall_m: 0.7520 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1841 - cross_loss: 0.3239 - dice_coef: 0.8159 - iou: 0.6895 - f1_m: 0.8557 - precision_m: 0.8423 - recall_m: 0.8703\n",
            "Epoch 45: val_loss did not improve from 0.26358\n",
            "60/60 [==============================] - 12s 199ms/step - loss: 0.1841 - cross_loss: 0.3239 - dice_coef: 0.8159 - iou: 0.6895 - f1_m: 0.8557 - precision_m: 0.8423 - recall_m: 0.8703 - val_loss: 0.2641 - val_cross_loss: 0.3184 - val_dice_coef: 0.7359 - val_iou: 0.5823 - val_f1_m: 0.7653 - val_precision_m: 0.7935 - val_recall_m: 0.7420 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1823 - cross_loss: 0.3241 - dice_coef: 0.8177 - iou: 0.6921 - f1_m: 0.8566 - precision_m: 0.8428 - recall_m: 0.8718\n",
            "Epoch 46: val_loss improved from 0.26358 to 0.26167, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1823 - cross_loss: 0.3241 - dice_coef: 0.8177 - iou: 0.6921 - f1_m: 0.8566 - precision_m: 0.8428 - recall_m: 0.8718 - val_loss: 0.2617 - val_cross_loss: 0.3174 - val_dice_coef: 0.7383 - val_iou: 0.5854 - val_f1_m: 0.7671 - val_precision_m: 0.7722 - val_recall_m: 0.7652 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1780 - cross_loss: 0.3245 - dice_coef: 0.8220 - iou: 0.6982 - f1_m: 0.8610 - precision_m: 0.8479 - recall_m: 0.8755\n",
            "Epoch 47: val_loss improved from 0.26167 to 0.26150, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 220ms/step - loss: 0.1780 - cross_loss: 0.3245 - dice_coef: 0.8220 - iou: 0.6982 - f1_m: 0.8610 - precision_m: 0.8479 - recall_m: 0.8755 - val_loss: 0.2615 - val_cross_loss: 0.3186 - val_dice_coef: 0.7385 - val_iou: 0.5856 - val_f1_m: 0.7665 - val_precision_m: 0.7934 - val_recall_m: 0.7447 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1737 - cross_loss: 0.3250 - dice_coef: 0.8263 - iou: 0.7045 - f1_m: 0.8656 - precision_m: 0.8540 - recall_m: 0.8785\n",
            "Epoch 48: val_loss did not improve from 0.26150\n",
            "60/60 [==============================] - 12s 198ms/step - loss: 0.1737 - cross_loss: 0.3250 - dice_coef: 0.8263 - iou: 0.7045 - f1_m: 0.8656 - precision_m: 0.8540 - recall_m: 0.8785 - val_loss: 0.2635 - val_cross_loss: 0.3184 - val_dice_coef: 0.7365 - val_iou: 0.5831 - val_f1_m: 0.7632 - val_precision_m: 0.7886 - val_recall_m: 0.7427 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1718 - cross_loss: 0.3252 - dice_coef: 0.8282 - iou: 0.7071 - f1_m: 0.8673 - precision_m: 0.8561 - recall_m: 0.8796\n",
            "Epoch 49: val_loss improved from 0.26150 to 0.26004, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1718 - cross_loss: 0.3252 - dice_coef: 0.8282 - iou: 0.7071 - f1_m: 0.8673 - precision_m: 0.8561 - recall_m: 0.8796 - val_loss: 0.2600 - val_cross_loss: 0.3189 - val_dice_coef: 0.7400 - val_iou: 0.5874 - val_f1_m: 0.7665 - val_precision_m: 0.7963 - val_recall_m: 0.7417 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1705 - cross_loss: 0.3253 - dice_coef: 0.8295 - iou: 0.7090 - f1_m: 0.8685 - precision_m: 0.8572 - recall_m: 0.8807\n",
            "Epoch 50: val_loss did not improve from 0.26004\n",
            "60/60 [==============================] - 12s 199ms/step - loss: 0.1705 - cross_loss: 0.3253 - dice_coef: 0.8295 - iou: 0.7090 - f1_m: 0.8685 - precision_m: 0.8572 - recall_m: 0.8807 - val_loss: 0.2641 - val_cross_loss: 0.3197 - val_dice_coef: 0.7359 - val_iou: 0.5823 - val_f1_m: 0.7623 - val_precision_m: 0.8143 - val_recall_m: 0.7192 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1689 - cross_loss: 0.3255 - dice_coef: 0.8311 - iou: 0.7114 - f1_m: 0.8697 - precision_m: 0.8582 - recall_m: 0.8821\n",
            "Epoch 51: val_loss did not improve from 0.26004\n",
            "60/60 [==============================] - 12s 196ms/step - loss: 0.1689 - cross_loss: 0.3255 - dice_coef: 0.8311 - iou: 0.7114 - f1_m: 0.8697 - precision_m: 0.8582 - recall_m: 0.8821 - val_loss: 0.2645 - val_cross_loss: 0.3193 - val_dice_coef: 0.7355 - val_iou: 0.5819 - val_f1_m: 0.7621 - val_precision_m: 0.8079 - val_recall_m: 0.7240 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1676 - cross_loss: 0.3256 - dice_coef: 0.8324 - iou: 0.7133 - f1_m: 0.8707 - precision_m: 0.8598 - recall_m: 0.8827\n",
            "Epoch 52: val_loss improved from 0.26004 to 0.25948, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 218ms/step - loss: 0.1676 - cross_loss: 0.3256 - dice_coef: 0.8324 - iou: 0.7133 - f1_m: 0.8707 - precision_m: 0.8598 - recall_m: 0.8827 - val_loss: 0.2595 - val_cross_loss: 0.3192 - val_dice_coef: 0.7405 - val_iou: 0.5882 - val_f1_m: 0.7665 - val_precision_m: 0.8002 - val_recall_m: 0.7381 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1659 - cross_loss: 0.3258 - dice_coef: 0.8342 - iou: 0.7159 - f1_m: 0.8722 - precision_m: 0.8622 - recall_m: 0.8832\n",
            "Epoch 53: val_loss did not improve from 0.25948\n",
            "60/60 [==============================] - 12s 200ms/step - loss: 0.1659 - cross_loss: 0.3258 - dice_coef: 0.8342 - iou: 0.7159 - f1_m: 0.8722 - precision_m: 0.8622 - recall_m: 0.8832 - val_loss: 0.2667 - val_cross_loss: 0.3194 - val_dice_coef: 0.7333 - val_iou: 0.5792 - val_f1_m: 0.7581 - val_precision_m: 0.8080 - val_recall_m: 0.7166 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1645 - cross_loss: 0.3260 - dice_coef: 0.8355 - iou: 0.7179 - f1_m: 0.8735 - precision_m: 0.8639 - recall_m: 0.8839\n",
            "Epoch 54: val_loss did not improve from 0.25948\n",
            "60/60 [==============================] - 12s 200ms/step - loss: 0.1645 - cross_loss: 0.3260 - dice_coef: 0.8355 - iou: 0.7179 - f1_m: 0.8735 - precision_m: 0.8639 - recall_m: 0.8839 - val_loss: 0.2683 - val_cross_loss: 0.3197 - val_dice_coef: 0.7317 - val_iou: 0.5772 - val_f1_m: 0.7557 - val_precision_m: 0.8146 - val_recall_m: 0.7074 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1632 - cross_loss: 0.3261 - dice_coef: 0.8368 - iou: 0.7198 - f1_m: 0.8745 - precision_m: 0.8646 - recall_m: 0.8854\n",
            "Epoch 55: val_loss did not improve from 0.25948\n",
            "60/60 [==============================] - 12s 200ms/step - loss: 0.1632 - cross_loss: 0.3261 - dice_coef: 0.8368 - iou: 0.7198 - f1_m: 0.8745 - precision_m: 0.8646 - recall_m: 0.8854 - val_loss: 0.2634 - val_cross_loss: 0.3199 - val_dice_coef: 0.7366 - val_iou: 0.5833 - val_f1_m: 0.7596 - val_precision_m: 0.8144 - val_recall_m: 0.7146 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1620 - cross_loss: 0.3262 - dice_coef: 0.8380 - iou: 0.7215 - f1_m: 0.8756 - precision_m: 0.8657 - recall_m: 0.8863\n",
            "Epoch 56: val_loss did not improve from 0.25948\n",
            "60/60 [==============================] - 12s 199ms/step - loss: 0.1620 - cross_loss: 0.3262 - dice_coef: 0.8380 - iou: 0.7215 - f1_m: 0.8756 - precision_m: 0.8657 - recall_m: 0.8863 - val_loss: 0.2655 - val_cross_loss: 0.3203 - val_dice_coef: 0.7345 - val_iou: 0.5808 - val_f1_m: 0.7581 - val_precision_m: 0.8248 - val_recall_m: 0.7042 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1609 - cross_loss: 0.3263 - dice_coef: 0.8391 - iou: 0.7232 - f1_m: 0.8767 - precision_m: 0.8671 - recall_m: 0.8871\n",
            "Epoch 57: val_loss did not improve from 0.25948\n",
            "\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "60/60 [==============================] - 12s 196ms/step - loss: 0.1609 - cross_loss: 0.3263 - dice_coef: 0.8391 - iou: 0.7232 - f1_m: 0.8767 - precision_m: 0.8671 - recall_m: 0.8871 - val_loss: 0.2751 - val_cross_loss: 0.3208 - val_dice_coef: 0.7249 - val_iou: 0.5689 - val_f1_m: 0.7476 - val_precision_m: 0.8445 - val_recall_m: 0.6734 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1589 - cross_loss: 0.3264 - dice_coef: 0.8411 - iou: 0.7261 - f1_m: 0.8788 - precision_m: 0.8667 - recall_m: 0.8920\n",
            "Epoch 58: val_loss improved from 0.25948 to 0.25244, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1589 - cross_loss: 0.3264 - dice_coef: 0.8411 - iou: 0.7261 - f1_m: 0.8788 - precision_m: 0.8667 - recall_m: 0.8920 - val_loss: 0.2524 - val_cross_loss: 0.3207 - val_dice_coef: 0.7476 - val_iou: 0.5971 - val_f1_m: 0.7709 - val_precision_m: 0.8240 - val_recall_m: 0.7272 - lr: 1.0000e-05\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1546 - cross_loss: 0.3269 - dice_coef: 0.8454 - iou: 0.7326 - f1_m: 0.8847 - precision_m: 0.8755 - recall_m: 0.8949\n",
            "Epoch 59: val_loss improved from 0.25244 to 0.25106, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 219ms/step - loss: 0.1546 - cross_loss: 0.3269 - dice_coef: 0.8454 - iou: 0.7326 - f1_m: 0.8847 - precision_m: 0.8755 - recall_m: 0.8949 - val_loss: 0.2511 - val_cross_loss: 0.3207 - val_dice_coef: 0.7489 - val_iou: 0.5989 - val_f1_m: 0.7723 - val_precision_m: 0.8226 - val_recall_m: 0.7306 - lr: 1.0000e-05\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1523 - cross_loss: 0.3271 - dice_coef: 0.8477 - iou: 0.7361 - f1_m: 0.8884 - precision_m: 0.8797 - recall_m: 0.8979\n",
            "Epoch 60: val_loss improved from 0.25106 to 0.25069, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 222ms/step - loss: 0.1523 - cross_loss: 0.3271 - dice_coef: 0.8477 - iou: 0.7361 - f1_m: 0.8884 - precision_m: 0.8797 - recall_m: 0.8979 - val_loss: 0.2507 - val_cross_loss: 0.3208 - val_dice_coef: 0.7493 - val_iou: 0.5994 - val_f1_m: 0.7726 - val_precision_m: 0.8223 - val_recall_m: 0.7314 - lr: 1.0000e-05\n",
            "Epoch 61/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1506 - cross_loss: 0.3273 - dice_coef: 0.8494 - iou: 0.7385 - f1_m: 0.8910 - precision_m: 0.8827 - recall_m: 0.9000\n",
            "Epoch 61: val_loss improved from 0.25069 to 0.25067, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 217ms/step - loss: 0.1506 - cross_loss: 0.3273 - dice_coef: 0.8494 - iou: 0.7385 - f1_m: 0.8910 - precision_m: 0.8827 - recall_m: 0.9000 - val_loss: 0.2507 - val_cross_loss: 0.3208 - val_dice_coef: 0.7493 - val_iou: 0.5994 - val_f1_m: 0.7725 - val_precision_m: 0.8223 - val_recall_m: 0.7313 - lr: 1.0000e-05\n",
            "Epoch 62/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1494 - cross_loss: 0.3274 - dice_coef: 0.8506 - iou: 0.7404 - f1_m: 0.8930 - precision_m: 0.8850 - recall_m: 0.9018\n",
            "Epoch 62: val_loss did not improve from 0.25067\n",
            "60/60 [==============================] - 12s 201ms/step - loss: 0.1494 - cross_loss: 0.3274 - dice_coef: 0.8506 - iou: 0.7404 - f1_m: 0.8930 - precision_m: 0.8850 - recall_m: 0.9018 - val_loss: 0.2507 - val_cross_loss: 0.3208 - val_dice_coef: 0.7493 - val_iou: 0.5994 - val_f1_m: 0.7725 - val_precision_m: 0.8223 - val_recall_m: 0.7313 - lr: 1.0000e-05\n",
            "Epoch 63/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1483 - cross_loss: 0.3275 - dice_coef: 0.8517 - iou: 0.7420 - f1_m: 0.8948 - precision_m: 0.8871 - recall_m: 0.9033\n",
            "Epoch 63: val_loss did not improve from 0.25067\n",
            "60/60 [==============================] - 12s 202ms/step - loss: 0.1483 - cross_loss: 0.3275 - dice_coef: 0.8517 - iou: 0.7420 - f1_m: 0.8948 - precision_m: 0.8871 - recall_m: 0.9033 - val_loss: 0.2508 - val_cross_loss: 0.3208 - val_dice_coef: 0.7492 - val_iou: 0.5992 - val_f1_m: 0.7724 - val_precision_m: 0.8222 - val_recall_m: 0.7312 - lr: 1.0000e-05\n",
            "Epoch 64/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1474 - cross_loss: 0.3276 - dice_coef: 0.8526 - iou: 0.7434 - f1_m: 0.8963 - precision_m: 0.8888 - recall_m: 0.9045\n",
            "Epoch 64: val_loss did not improve from 0.25067\n",
            "60/60 [==============================] - 12s 198ms/step - loss: 0.1474 - cross_loss: 0.3276 - dice_coef: 0.8526 - iou: 0.7434 - f1_m: 0.8963 - precision_m: 0.8888 - recall_m: 0.9045 - val_loss: 0.2509 - val_cross_loss: 0.3207 - val_dice_coef: 0.7491 - val_iou: 0.5991 - val_f1_m: 0.7723 - val_precision_m: 0.8220 - val_recall_m: 0.7311 - lr: 1.0000e-05\n",
            "Epoch 65/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1466 - cross_loss: 0.3277 - dice_coef: 0.8534 - iou: 0.7446 - f1_m: 0.8977 - precision_m: 0.8903 - recall_m: 0.9057\n",
            "Epoch 65: val_loss did not improve from 0.25067\n",
            "\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "60/60 [==============================] - 12s 198ms/step - loss: 0.1466 - cross_loss: 0.3277 - dice_coef: 0.8534 - iou: 0.7446 - f1_m: 0.8977 - precision_m: 0.8903 - recall_m: 0.9057 - val_loss: 0.2509 - val_cross_loss: 0.3207 - val_dice_coef: 0.7491 - val_iou: 0.5990 - val_f1_m: 0.7722 - val_precision_m: 0.8218 - val_recall_m: 0.7311 - lr: 1.0000e-05\n",
            "Epoch 66/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1460 - cross_loss: 0.3278 - dice_coef: 0.8540 - iou: 0.7455 - f1_m: 0.8981 - precision_m: 0.8930 - recall_m: 0.9038\n",
            "Epoch 66: val_loss improved from 0.25067 to 0.24976, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 221ms/step - loss: 0.1460 - cross_loss: 0.3278 - dice_coef: 0.8540 - iou: 0.7455 - f1_m: 0.8981 - precision_m: 0.8930 - recall_m: 0.9038 - val_loss: 0.2498 - val_cross_loss: 0.3206 - val_dice_coef: 0.7502 - val_iou: 0.6005 - val_f1_m: 0.7731 - val_precision_m: 0.8183 - val_recall_m: 0.7356 - lr: 1.0000e-06\n",
            "Epoch 67/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1458 - cross_loss: 0.3278 - dice_coef: 0.8542 - iou: 0.7459 - f1_m: 0.8987 - precision_m: 0.8918 - recall_m: 0.9061\n",
            "Epoch 67: val_loss improved from 0.24976 to 0.24954, saving model to files/model.h5\n",
            "60/60 [==============================] - 13s 223ms/step - loss: 0.1458 - cross_loss: 0.3278 - dice_coef: 0.8542 - iou: 0.7459 - f1_m: 0.8987 - precision_m: 0.8918 - recall_m: 0.9061 - val_loss: 0.2495 - val_cross_loss: 0.3206 - val_dice_coef: 0.7505 - val_iou: 0.6008 - val_f1_m: 0.7733 - val_precision_m: 0.8175 - val_recall_m: 0.7365 - lr: 1.0000e-06\n",
            "Epoch 68/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1457 - cross_loss: 0.3278 - dice_coef: 0.8543 - iou: 0.7460 - f1_m: 0.8989 - precision_m: 0.8918 - recall_m: 0.9066\n",
            "Epoch 68: val_loss improved from 0.24954 to 0.24951, saving model to files/model.h5\n",
            "60/60 [==============================] - 14s 226ms/step - loss: 0.1457 - cross_loss: 0.3278 - dice_coef: 0.8543 - iou: 0.7460 - f1_m: 0.8989 - precision_m: 0.8918 - recall_m: 0.9066 - val_loss: 0.2495 - val_cross_loss: 0.3206 - val_dice_coef: 0.7505 - val_iou: 0.6008 - val_f1_m: 0.7732 - val_precision_m: 0.8173 - val_recall_m: 0.7366 - lr: 1.0000e-06\n",
            "Epoch 69/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1456 - cross_loss: 0.3278 - dice_coef: 0.8544 - iou: 0.7462 - f1_m: 0.8991 - precision_m: 0.8919 - recall_m: 0.9068\n",
            "Epoch 69: val_loss did not improve from 0.24951\n",
            "60/60 [==============================] - 12s 200ms/step - loss: 0.1456 - cross_loss: 0.3278 - dice_coef: 0.8544 - iou: 0.7462 - f1_m: 0.8991 - precision_m: 0.8919 - recall_m: 0.9068 - val_loss: 0.2495 - val_cross_loss: 0.3206 - val_dice_coef: 0.7505 - val_iou: 0.6008 - val_f1_m: 0.7732 - val_precision_m: 0.8173 - val_recall_m: 0.7365 - lr: 1.0000e-06\n",
            "Epoch 70/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1455 - cross_loss: 0.3278 - dice_coef: 0.8545 - iou: 0.7463 - f1_m: 0.8992 - precision_m: 0.8921 - recall_m: 0.9070\n",
            "Epoch 70: val_loss did not improve from 0.24951\n",
            "60/60 [==============================] - 12s 200ms/step - loss: 0.1455 - cross_loss: 0.3278 - dice_coef: 0.8545 - iou: 0.7463 - f1_m: 0.8992 - precision_m: 0.8921 - recall_m: 0.9070 - val_loss: 0.2495 - val_cross_loss: 0.3206 - val_dice_coef: 0.7505 - val_iou: 0.6008 - val_f1_m: 0.7732 - val_precision_m: 0.8173 - val_recall_m: 0.7365 - lr: 1.0000e-06\n",
            "Epoch 71/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1454 - cross_loss: 0.3278 - dice_coef: 0.8546 - iou: 0.7464 - f1_m: 0.8994 - precision_m: 0.8923 - recall_m: 0.9071\n",
            "Epoch 71: val_loss did not improve from 0.24951\n",
            "60/60 [==============================] - 12s 201ms/step - loss: 0.1454 - cross_loss: 0.3278 - dice_coef: 0.8546 - iou: 0.7464 - f1_m: 0.8994 - precision_m: 0.8923 - recall_m: 0.9071 - val_loss: 0.2495 - val_cross_loss: 0.3206 - val_dice_coef: 0.7505 - val_iou: 0.6008 - val_f1_m: 0.7732 - val_precision_m: 0.8173 - val_recall_m: 0.7364 - lr: 1.0000e-06\n",
            "Epoch 72/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1453 - cross_loss: 0.3278 - dice_coef: 0.8547 - iou: 0.7466 - f1_m: 0.8996 - precision_m: 0.8925 - recall_m: 0.9073\n",
            "Epoch 72: val_loss did not improve from 0.24951\n",
            "60/60 [==============================] - 12s 198ms/step - loss: 0.1453 - cross_loss: 0.3278 - dice_coef: 0.8547 - iou: 0.7466 - f1_m: 0.8996 - precision_m: 0.8925 - recall_m: 0.9073 - val_loss: 0.2496 - val_cross_loss: 0.3206 - val_dice_coef: 0.7504 - val_iou: 0.6008 - val_f1_m: 0.7731 - val_precision_m: 0.8173 - val_recall_m: 0.7363 - lr: 1.0000e-06\n",
            "Epoch 73/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1452 - cross_loss: 0.3278 - dice_coef: 0.8548 - iou: 0.7467 - f1_m: 0.8997 - precision_m: 0.8926 - recall_m: 0.9074\n",
            "Epoch 73: val_loss did not improve from 0.24951\n",
            "60/60 [==============================] - 12s 199ms/step - loss: 0.1452 - cross_loss: 0.3278 - dice_coef: 0.8548 - iou: 0.7467 - f1_m: 0.8997 - precision_m: 0.8926 - recall_m: 0.9074 - val_loss: 0.2496 - val_cross_loss: 0.3206 - val_dice_coef: 0.7504 - val_iou: 0.6008 - val_f1_m: 0.7731 - val_precision_m: 0.8174 - val_recall_m: 0.7363 - lr: 1.0000e-06\n",
            "Epoch 74/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1452 - cross_loss: 0.3278 - dice_coef: 0.8548 - iou: 0.7468 - f1_m: 0.8999 - precision_m: 0.8928 - recall_m: 0.9075\n",
            "Epoch 74: val_loss did not improve from 0.24951\n",
            "60/60 [==============================] - 12s 198ms/step - loss: 0.1452 - cross_loss: 0.3278 - dice_coef: 0.8548 - iou: 0.7468 - f1_m: 0.8999 - precision_m: 0.8928 - recall_m: 0.9075 - val_loss: 0.2496 - val_cross_loss: 0.3206 - val_dice_coef: 0.7504 - val_iou: 0.6007 - val_f1_m: 0.7731 - val_precision_m: 0.8174 - val_recall_m: 0.7362 - lr: 1.0000e-06\n",
            "Epoch 75/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1451 - cross_loss: 0.3278 - dice_coef: 0.8549 - iou: 0.7470 - f1_m: 0.9000 - precision_m: 0.8930 - recall_m: 0.9077\n",
            "Epoch 75: val_loss did not improve from 0.24951\n",
            "60/60 [==============================] - 12s 201ms/step - loss: 0.1451 - cross_loss: 0.3278 - dice_coef: 0.8549 - iou: 0.7470 - f1_m: 0.9000 - precision_m: 0.8930 - recall_m: 0.9077 - val_loss: 0.2496 - val_cross_loss: 0.3206 - val_dice_coef: 0.7504 - val_iou: 0.6007 - val_f1_m: 0.7731 - val_precision_m: 0.8175 - val_recall_m: 0.7362 - lr: 1.0000e-06\n",
            "Epoch 76/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1450 - cross_loss: 0.3278 - dice_coef: 0.8550 - iou: 0.7471 - f1_m: 0.9002 - precision_m: 0.8932 - recall_m: 0.9078\n",
            "Epoch 76: val_loss did not improve from 0.24951\n",
            "60/60 [==============================] - 12s 200ms/step - loss: 0.1450 - cross_loss: 0.3278 - dice_coef: 0.8550 - iou: 0.7471 - f1_m: 0.9002 - precision_m: 0.8932 - recall_m: 0.9078 - val_loss: 0.2496 - val_cross_loss: 0.3206 - val_dice_coef: 0.7504 - val_iou: 0.6007 - val_f1_m: 0.7731 - val_precision_m: 0.8175 - val_recall_m: 0.7361 - lr: 1.0000e-06\n",
            "Epoch 77/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1449 - cross_loss: 0.3279 - dice_coef: 0.8551 - iou: 0.7472 - f1_m: 0.9003 - precision_m: 0.8933 - recall_m: 0.9079\n",
            "Epoch 77: val_loss did not improve from 0.24951\n",
            "60/60 [==============================] - 12s 200ms/step - loss: 0.1449 - cross_loss: 0.3279 - dice_coef: 0.8551 - iou: 0.7472 - f1_m: 0.9003 - precision_m: 0.8933 - recall_m: 0.9079 - val_loss: 0.2497 - val_cross_loss: 0.3206 - val_dice_coef: 0.7503 - val_iou: 0.6007 - val_f1_m: 0.7730 - val_precision_m: 0.8175 - val_recall_m: 0.7360 - lr: 1.0000e-06\n",
            "Epoch 78/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1448 - cross_loss: 0.3279 - dice_coef: 0.8552 - iou: 0.7474 - f1_m: 0.9005 - precision_m: 0.8935 - recall_m: 0.9081\n",
            "Epoch 78: val_loss did not improve from 0.24951\n",
            "60/60 [==============================] - 12s 200ms/step - loss: 0.1448 - cross_loss: 0.3279 - dice_coef: 0.8552 - iou: 0.7474 - f1_m: 0.9005 - precision_m: 0.8935 - recall_m: 0.9081 - val_loss: 0.2497 - val_cross_loss: 0.3206 - val_dice_coef: 0.7503 - val_iou: 0.6006 - val_f1_m: 0.7730 - val_precision_m: 0.8175 - val_recall_m: 0.7359 - lr: 1.0000e-06\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "\n",
        "\n",
        "\n",
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
        "    return x, y\n",
        "\n",
        "def shuffling(x, y):\n",
        "    x, y = shuffle(x, y, random_state=42)\n",
        "    return x, y\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY);\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=-1)  \n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=-1)              ## (512, 512, 1)\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 1])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(X, Y, batch_size=2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(4)\n",
        "    return dataset\n",
        "\n",
        "def main():\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \n",
        "    create_dir(\"files\")\n",
        "\n",
        "\n",
        "    batch_size = 2\n",
        "    lr = 1e-4\n",
        "    num_epochs = 100\n",
        "    model_path = os.path.join(\"files\", \"model.h5\")\n",
        "    csv_path = os.path.join(\"files\", \"data.csv\")\n",
        "\n",
        "    #loading the dataset\n",
        "    dataset_path = \"new_data\"\n",
        "    train_path = os.path.join(dataset_path, \"train\")\n",
        "    valid_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "    train_x, train_y = load_data(train_path)\n",
        "    train_x, train_y = shuffling(train_x, train_y)\n",
        "    valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "    train_steps = len(train_x)//batch_size\n",
        "    valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "    if len(train_x) % batch_size != 0:\n",
        "        train_steps += 1\n",
        "    if len(valid_x) % batch_size != 0:\n",
        "        valid_setps += 1\n",
        "\n",
        "    \n",
        "    model = build_unet((H, W, 1))\n",
        "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[cross_loss, dice_coef, iou,f1_m,precision_m, recall_m])\n",
        "    # model.summary()\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        TensorBoard(),\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
        "    ]\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=valid_dataset,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_setps,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43hSmV0IVroj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH5Az3_wVien",
        "outputId": "97c69de1-4d8f-45b2-98ee-8b3eccde193d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.94419\n",
            "F1: 0.94931\n",
            "Jaccard: 0.95248\n",
            "Recall: 0.95596\n",
            "Precision: 0.95251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY);\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return ori_x, x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (256, 256)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.int32)\n",
        "    return ori_x, x\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
        "    return x, y\n",
        "def save_results(ori_x, ori_y, y_pred, save_image_path):\n",
        "    \n",
        "    \n",
        "    ori_y = np.expand_dims(ori_y, axis=-1)\n",
        "    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)\n",
        "    \n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)*255\n",
        "    #y_pred = np.column_stack([y_pred, y_pred, y_pred]) *255\n",
        "   \n",
        "    #cat_images = np.column_stack([ori_x, ori_y, y_pred]) \n",
        "    cv2.imwrite(save_image_path, y_pred)\n",
        "\n",
        "def main():\n",
        "    create_dir(\"results\")\n",
        "\n",
        " \n",
        "    with CustomObjectScope({'cross_loss' : cross_loss, 'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss,'f1_m': f1_m, 'precision_m': precision_m,'recall_m':recall_m}):\n",
        "        model = tf.keras.models.load_model(\"files/model.h5\")\n",
        "\n",
        "    dataset_path = os.path.join(\"new_data\", \"test\")\n",
        "    test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "    SCORE = []\n",
        "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "      \n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        \n",
        "        ori_x, x = read_image(x)\n",
        "        ori_y, y = read_mask(y)\n",
        "      \n",
        "\n",
        "        \n",
        "\n",
        "        #prediction\n",
        "        y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "        y_pred = y_pred > 0.5\n",
        "        y_pred = y_pred.astype(np.int32)\n",
        "        y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "      \n",
        "        save_image_path = f\"results/{name}.png\"\n",
        "        save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "        #flattening the array\n",
        "        y = y.flatten()\n",
        "        y_pred = y_pred.flatten()\n",
        "\n",
        "        #metrics\n",
        "        acc_value = accuracy_score(y, y_pred)\n",
        "        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"weighted\")\n",
        "        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"weighted\")\n",
        "        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"weighted\")\n",
        "        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"weighted\")\n",
        "        SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "    score = [s[1:] for s in SCORE]\n",
        "    score = np.mean(score, axis=-1)\n",
        "    print(f\"Accuracy: {score[1]:0.5f}\")\n",
        "    print(f\"F1: {score[2]:0.5f}\")\n",
        "    print(f\"Jaccard: {score[3]:0.5f}\")\n",
        "    print(f\"Recall: {score[4]:0.5f}\")\n",
        "    print(f\"Precision: {score[5]:0.5f}\")\n",
        "\n",
        "    df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "    df.to_csv(\"files/score.csv\")\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "   \n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "1HdKVHUK-BT_",
        "outputId": "faf9f096-d959-46c0-9cc6-389dc152b867"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#accuracy dice coefficient precision graphs\n",
        "import io\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "path = \"/content/drive/MyDrive/DRIVE_Data/files/data.csv\"\n",
        "data_csv = pd.read_csv(path)\n",
        "#data_csv\n",
        "\n",
        "#shows how the val_loss decreases with each epoch\n",
        "\n",
        "lines = data_csv.plot.line(x='epoch', y=['loss', 'val_loss'])\n",
        "plt.title('Validation Loss Curve')\n",
        "plt.ylabel('Val_Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "lines = data_csv.plot.line(x='epoch', y=['dice_coef', 'val_dice_coef'])\n",
        "plt.title('Dice Coefficient Curves U-Net')\n",
        "plt.ylabel('Dice Coefficient')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "lines = data_csv.plot.line(x='epoch', y=['precision_m', 'val_precision_m'])\n",
        "plt.title('Precision Curves U-Net')\n",
        "plt.ylabel('Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "fundus_imaging_unet (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}